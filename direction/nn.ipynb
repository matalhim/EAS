{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_1</th>\n",
       "      <th>Y_1</th>\n",
       "      <th>Z_1</th>\n",
       "      <th>t_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>Y_2</th>\n",
       "      <th>Z_2</th>\n",
       "      <th>t_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>Y_3</th>\n",
       "      <th>Z_3</th>\n",
       "      <th>t_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>Y_4</th>\n",
       "      <th>Z_4</th>\n",
       "      <th>t_4</th>\n",
       "      <th>theta</th>\n",
       "      <th>phi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-25.359</td>\n",
       "      <td>5.885</td>\n",
       "      <td>-6.684</td>\n",
       "      <td>78.875263</td>\n",
       "      <td>-37.609</td>\n",
       "      <td>5.885</td>\n",
       "      <td>-6.684</td>\n",
       "      <td>74.805427</td>\n",
       "      <td>-37.609</td>\n",
       "      <td>-7.315</td>\n",
       "      <td>-6.684</td>\n",
       "      <td>99.676584</td>\n",
       "      <td>-25.359</td>\n",
       "      <td>-7.315</td>\n",
       "      <td>-6.684</td>\n",
       "      <td>103.746420</td>\n",
       "      <td>35</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-25.359</td>\n",
       "      <td>37.335</td>\n",
       "      <td>-6.684</td>\n",
       "      <td>19.617847</td>\n",
       "      <td>-37.609</td>\n",
       "      <td>37.335</td>\n",
       "      <td>-6.684</td>\n",
       "      <td>15.548011</td>\n",
       "      <td>-37.609</td>\n",
       "      <td>24.135</td>\n",
       "      <td>-6.684</td>\n",
       "      <td>40.419168</td>\n",
       "      <td>-25.359</td>\n",
       "      <td>24.135</td>\n",
       "      <td>-6.684</td>\n",
       "      <td>44.489004</td>\n",
       "      <td>35</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.479</td>\n",
       "      <td>12.650</td>\n",
       "      <td>0.000</td>\n",
       "      <td>58.443040</td>\n",
       "      <td>-6.872</td>\n",
       "      <td>12.650</td>\n",
       "      <td>0.000</td>\n",
       "      <td>54.007417</td>\n",
       "      <td>-6.872</td>\n",
       "      <td>-12.630</td>\n",
       "      <td>0.000</td>\n",
       "      <td>101.639451</td>\n",
       "      <td>6.479</td>\n",
       "      <td>-12.630</td>\n",
       "      <td>0.000</td>\n",
       "      <td>106.075074</td>\n",
       "      <td>35</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      X_1     Y_1    Z_1        t_1     X_2     Y_2    Z_2        t_2     X_3  \\\n",
       "0 -25.359   5.885 -6.684  78.875263 -37.609   5.885 -6.684  74.805427 -37.609   \n",
       "1 -25.359  37.335 -6.684  19.617847 -37.609  37.335 -6.684  15.548011 -37.609   \n",
       "2   6.479  12.650  0.000  58.443040  -6.872  12.650  0.000  54.007417  -6.872   \n",
       "\n",
       "      Y_3    Z_3         t_3     X_4     Y_4    Z_4         t_4  theta  phi  \n",
       "0  -7.315 -6.684   99.676584 -25.359  -7.315 -6.684  103.746420     35  100  \n",
       "1  24.135 -6.684   40.419168 -25.359  24.135 -6.684   44.489004     35  100  \n",
       "2 -12.630  0.000  101.639451   6.479 -12.630  0.000  106.075074     35  100  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/clusters_synthetic_dataset.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_1</th>\n",
       "      <th>Y_1</th>\n",
       "      <th>Z_1</th>\n",
       "      <th>t_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>Y_2</th>\n",
       "      <th>Z_2</th>\n",
       "      <th>t_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>Y_3</th>\n",
       "      <th>Z_3</th>\n",
       "      <th>t_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>Y_4</th>\n",
       "      <th>Z_4</th>\n",
       "      <th>t_4</th>\n",
       "      <th>theta</th>\n",
       "      <th>phi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-25.359</td>\n",
       "      <td>5.885</td>\n",
       "      <td>-6.684</td>\n",
       "      <td>4.069836</td>\n",
       "      <td>-37.609</td>\n",
       "      <td>5.885</td>\n",
       "      <td>-6.684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-37.609</td>\n",
       "      <td>-7.315</td>\n",
       "      <td>-6.684</td>\n",
       "      <td>24.871157</td>\n",
       "      <td>-25.359</td>\n",
       "      <td>-7.315</td>\n",
       "      <td>-6.684</td>\n",
       "      <td>28.940993</td>\n",
       "      <td>35</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-25.359</td>\n",
       "      <td>37.335</td>\n",
       "      <td>-6.684</td>\n",
       "      <td>4.069836</td>\n",
       "      <td>-37.609</td>\n",
       "      <td>37.335</td>\n",
       "      <td>-6.684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-37.609</td>\n",
       "      <td>24.135</td>\n",
       "      <td>-6.684</td>\n",
       "      <td>24.871157</td>\n",
       "      <td>-25.359</td>\n",
       "      <td>24.135</td>\n",
       "      <td>-6.684</td>\n",
       "      <td>28.940993</td>\n",
       "      <td>35</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.479</td>\n",
       "      <td>12.650</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.435623</td>\n",
       "      <td>-6.872</td>\n",
       "      <td>12.650</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.872</td>\n",
       "      <td>-12.630</td>\n",
       "      <td>0.000</td>\n",
       "      <td>47.632034</td>\n",
       "      <td>6.479</td>\n",
       "      <td>-12.630</td>\n",
       "      <td>0.000</td>\n",
       "      <td>52.067657</td>\n",
       "      <td>35</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      X_1     Y_1    Z_1       t_1     X_2     Y_2    Z_2  t_2     X_3  \\\n",
       "0 -25.359   5.885 -6.684  4.069836 -37.609   5.885 -6.684  0.0 -37.609   \n",
       "1 -25.359  37.335 -6.684  4.069836 -37.609  37.335 -6.684  0.0 -37.609   \n",
       "2   6.479  12.650  0.000  4.435623  -6.872  12.650  0.000  0.0  -6.872   \n",
       "\n",
       "      Y_3    Z_3        t_3     X_4     Y_4    Z_4        t_4  theta  phi  \n",
       "0  -7.315 -6.684  24.871157 -25.359  -7.315 -6.684  28.940993     35  100  \n",
       "1  24.135 -6.684  24.871157 -25.359  24.135 -6.684  28.940993     35  100  \n",
       "2 -12.630  0.000  47.632034   6.479 -12.630  0.000  52.067657     35  100  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_columns = ['t_1', 't_2', 't_3', 't_4']\n",
    "df['min_t'] = df[t_columns].min(axis=1)\n",
    "\n",
    "for t_col in t_columns:\n",
    "    df[t_col] = df[t_col] - df['min_t']\n",
    "\n",
    "df.drop('min_t', axis=1, inplace=True)\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(df)):\n",
    "    if random.random() < 0.5:\n",
    "        t_col = random.choice(t_columns)\n",
    "        df.at[idx, t_col] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_1</th>\n",
       "      <th>Y_1</th>\n",
       "      <th>Z_1</th>\n",
       "      <th>t_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>Y_2</th>\n",
       "      <th>Z_2</th>\n",
       "      <th>t_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>Y_3</th>\n",
       "      <th>Z_3</th>\n",
       "      <th>t_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>Y_4</th>\n",
       "      <th>Z_4</th>\n",
       "      <th>t_4</th>\n",
       "      <th>theta</th>\n",
       "      <th>phi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-25.359</td>\n",
       "      <td>5.885</td>\n",
       "      <td>-6.684</td>\n",
       "      <td>4.069836</td>\n",
       "      <td>-37.609</td>\n",
       "      <td>5.885</td>\n",
       "      <td>-6.684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-37.609</td>\n",
       "      <td>-7.315</td>\n",
       "      <td>-6.684</td>\n",
       "      <td>24.871157</td>\n",
       "      <td>-25.359</td>\n",
       "      <td>-7.315</td>\n",
       "      <td>-6.684</td>\n",
       "      <td>28.940993</td>\n",
       "      <td>35</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-25.359</td>\n",
       "      <td>37.335</td>\n",
       "      <td>-6.684</td>\n",
       "      <td>4.069836</td>\n",
       "      <td>-37.609</td>\n",
       "      <td>37.335</td>\n",
       "      <td>-6.684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-37.609</td>\n",
       "      <td>24.135</td>\n",
       "      <td>-6.684</td>\n",
       "      <td>24.871157</td>\n",
       "      <td>-25.359</td>\n",
       "      <td>24.135</td>\n",
       "      <td>-6.684</td>\n",
       "      <td>28.940993</td>\n",
       "      <td>35</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.479</td>\n",
       "      <td>12.650</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.435623</td>\n",
       "      <td>-6.872</td>\n",
       "      <td>12.650</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.872</td>\n",
       "      <td>-12.630</td>\n",
       "      <td>0.000</td>\n",
       "      <td>47.632034</td>\n",
       "      <td>6.479</td>\n",
       "      <td>-12.630</td>\n",
       "      <td>0.000</td>\n",
       "      <td>52.067657</td>\n",
       "      <td>35</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.369</td>\n",
       "      <td>10.956</td>\n",
       "      <td>-14.946</td>\n",
       "      <td>4.075883</td>\n",
       "      <td>22.469</td>\n",
       "      <td>10.956</td>\n",
       "      <td>-15.266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.469</td>\n",
       "      <td>-3.952</td>\n",
       "      <td>-15.346</td>\n",
       "      <td>28.307926</td>\n",
       "      <td>37.369</td>\n",
       "      <td>-3.952</td>\n",
       "      <td>-15.076</td>\n",
       "      <td>32.520428</td>\n",
       "      <td>35</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37.369</td>\n",
       "      <td>45.572</td>\n",
       "      <td>-16.166</td>\n",
       "      <td>3.975419</td>\n",
       "      <td>22.977</td>\n",
       "      <td>45.572</td>\n",
       "      <td>-16.461</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.977</td>\n",
       "      <td>28.482</td>\n",
       "      <td>-16.111</td>\n",
       "      <td>31.244273</td>\n",
       "      <td>37.367</td>\n",
       "      <td>28.482</td>\n",
       "      <td>-16.511</td>\n",
       "      <td>37.118043</td>\n",
       "      <td>35</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      X_1     Y_1     Z_1       t_1     X_2     Y_2     Z_2  t_2     X_3  \\\n",
       "0 -25.359   5.885  -6.684  4.069836 -37.609   5.885  -6.684  0.0 -37.609   \n",
       "1 -25.359  37.335  -6.684  4.069836 -37.609  37.335  -6.684  0.0 -37.609   \n",
       "2   6.479  12.650   0.000  4.435623  -6.872  12.650   0.000  0.0  -6.872   \n",
       "3  37.369  10.956 -14.946  4.075883  22.469  10.956 -15.266  0.0  22.469   \n",
       "4  37.369  45.572 -16.166  3.975419  22.977  45.572 -16.461  0.0  22.977   \n",
       "\n",
       "      Y_3     Z_3        t_3     X_4     Y_4     Z_4        t_4  theta  phi  \n",
       "0  -7.315  -6.684  24.871157 -25.359  -7.315  -6.684  28.940993     35  100  \n",
       "1  24.135  -6.684  24.871157 -25.359  24.135  -6.684  28.940993     35  100  \n",
       "2 -12.630   0.000  47.632034   6.479 -12.630   0.000  52.067657     35  100  \n",
       "3  -3.952 -15.346  28.307926  37.369  -3.952 -15.076  32.520428     35  100  \n",
       "4  28.482 -16.111  31.244273  37.367  28.482 -16.511  37.118043     35  100  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['theta', 'phi']).values\n",
    "y = df[['theta', 'phi']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_tensor = torch.isnan(X_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test,  mask_train, mask_test = train_test_split(\n",
    "    X_tensor, y_tensor, mask_tensor, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "mask_train, mask_test = mask_train.to(device), mask_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([52142, 16]) torch.Size([52142, 16]) torch.Size([52142, 2])\n"
     ]
    }
   ],
   "source": [
    "print(mask_train.shape, X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThetaPhiPredictionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ThetaPhiPredictionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(X_train.shape[1], 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ThetaPhiPredictionModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, mask_train, criterion, optimizer, epochs=3000):\n",
    "    for epoch in tqdm(range(epochs), desc=\"Training\", ncols=100, position=0, leave=True):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Применяем маску для исключения NaN значений в X_train\n",
    "        # Маска для строк, где нет NaN в X_train\n",
    "        valid_mask = ~torch.isnan(X_train).any(dim=1)\n",
    "\n",
    "        # Применяем маску на входные данные и целевые значения\n",
    "        # Оставляем только строки без NaN в X_train\n",
    "        X_train_valid = X_train[valid_mask]\n",
    "        # Оставляем только соответствующие целевые значения\n",
    "        y_train_valid = y_train[valid_mask]\n",
    "\n",
    "        # Прогоняем данные через модель\n",
    "        y_pred = model(X_train_valid)\n",
    "\n",
    "        # Рассчитываем потери\n",
    "        loss = criterion(y_pred, y_train_valid)\n",
    "\n",
    "        loss.backward()  # Обратное распространение\n",
    "        optimizer.step()  # Обновление параметров модели\n",
    "\n",
    "        tqdm.write(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "305d4da387414ba1a85e5776de4906f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|                                                            | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3000], Loss: 22.5973\n",
      "Epoch [2/3000], Loss: 22.5841\n",
      "Epoch [3/3000], Loss: 22.5709\n",
      "Epoch [4/3000], Loss: 22.5578\n",
      "Epoch [5/3000], Loss: 22.5446\n",
      "Epoch [6/3000], Loss: 22.5315\n",
      "Epoch [7/3000], Loss: 22.5184\n",
      "Epoch [8/3000], Loss: 22.5053\n",
      "Epoch [9/3000], Loss: 22.4922\n",
      "Epoch [10/3000], Loss: 22.4790\n",
      "Epoch [11/3000], Loss: 22.4658\n",
      "Epoch [12/3000], Loss: 22.4526\n",
      "Epoch [13/3000], Loss: 22.4395\n",
      "Epoch [14/3000], Loss: 22.4263\n",
      "Epoch [15/3000], Loss: 22.4131\n",
      "Epoch [16/3000], Loss: 22.3998\n",
      "Epoch [17/3000], Loss: 22.3866\n",
      "Epoch [18/3000], Loss: 22.3733\n",
      "Epoch [19/3000], Loss: 22.3601\n",
      "Epoch [20/3000], Loss: 22.3468\n",
      "Epoch [21/3000], Loss: 22.3335\n",
      "Epoch [22/3000], Loss: 22.3201\n",
      "Epoch [23/3000], Loss: 22.3066\n",
      "Epoch [24/3000], Loss: 22.2931\n",
      "Epoch [25/3000], Loss: 22.2796\n",
      "Epoch [26/3000], Loss: 22.2661\n",
      "Epoch [27/3000], Loss: 22.2525\n",
      "Epoch [28/3000], Loss: 22.2388\n",
      "Epoch [29/3000], Loss: 22.2251\n",
      "Epoch [30/3000], Loss: 22.2113\n",
      "Epoch [31/3000], Loss: 22.1975\n",
      "Epoch [32/3000], Loss: 22.1836\n",
      "Epoch [33/3000], Loss: 22.1698\n",
      "Epoch [34/3000], Loss: 22.1559\n",
      "Epoch [35/3000], Loss: 22.1419\n",
      "Epoch [36/3000], Loss: 22.1278\n",
      "Epoch [37/3000], Loss: 22.1136\n",
      "Epoch [38/3000], Loss: 22.0995\n",
      "Epoch [39/3000], Loss: 22.0853\n",
      "Epoch [40/3000], Loss: 22.0711\n",
      "Epoch [41/3000], Loss: 22.0568\n",
      "Epoch [42/3000], Loss: 22.0426\n",
      "Epoch [43/3000], Loss: 22.0284\n",
      "Epoch [44/3000], Loss: 22.0141\n",
      "Epoch [45/3000], Loss: 22.0000\n",
      "Epoch [46/3000], Loss: 21.9858\n",
      "Epoch [47/3000], Loss: 21.9716\n",
      "Epoch [48/3000], Loss: 21.9574\n",
      "Epoch [49/3000], Loss: 21.9433\n",
      "Epoch [50/3000], Loss: 21.9291\n",
      "Epoch [51/3000], Loss: 21.9149\n",
      "Epoch [52/3000], Loss: 21.9008\n",
      "Epoch [53/3000], Loss: 21.8866\n",
      "Epoch [54/3000], Loss: 21.8724\n",
      "Epoch [55/3000], Loss: 21.8583\n",
      "Epoch [56/3000], Loss: 21.8442\n",
      "Epoch [57/3000], Loss: 21.8301\n",
      "Epoch [58/3000], Loss: 21.8160\n",
      "Epoch [59/3000], Loss: 21.8020\n",
      "Epoch [60/3000], Loss: 21.7879\n",
      "Epoch [61/3000], Loss: 21.7738\n",
      "Epoch [62/3000], Loss: 21.7598\n",
      "Epoch [63/3000], Loss: 21.7457\n",
      "Epoch [64/3000], Loss: 21.7316\n",
      "Epoch [65/3000], Loss: 21.7176\n",
      "Epoch [66/3000], Loss: 21.7035\n",
      "Epoch [67/3000], Loss: 21.6895\n",
      "Epoch [68/3000], Loss: 21.6755\n",
      "Epoch [69/3000], Loss: 21.6616\n",
      "Epoch [70/3000], Loss: 21.6476\n",
      "Epoch [71/3000], Loss: 21.6334\n",
      "Epoch [72/3000], Loss: 21.6191\n",
      "Epoch [73/3000], Loss: 21.6048\n",
      "Epoch [74/3000], Loss: 21.5905\n",
      "Epoch [75/3000], Loss: 21.5761\n",
      "Epoch [76/3000], Loss: 21.5616\n",
      "Epoch [77/3000], Loss: 21.5472\n",
      "Epoch [78/3000], Loss: 21.5327\n",
      "Epoch [79/3000], Loss: 21.5182\n",
      "Epoch [80/3000], Loss: 21.5038\n",
      "Epoch [81/3000], Loss: 21.4894\n",
      "Epoch [82/3000], Loss: 21.4749\n",
      "Epoch [83/3000], Loss: 21.4605\n",
      "Epoch [84/3000], Loss: 21.4462\n",
      "Epoch [85/3000], Loss: 21.4319\n",
      "Epoch [86/3000], Loss: 21.4176\n",
      "Epoch [87/3000], Loss: 21.4033\n",
      "Epoch [88/3000], Loss: 21.3891\n",
      "Epoch [89/3000], Loss: 21.3749\n",
      "Epoch [90/3000], Loss: 21.3607\n",
      "Epoch [91/3000], Loss: 21.3466\n",
      "Epoch [92/3000], Loss: 21.3326\n",
      "Epoch [93/3000], Loss: 21.3185\n",
      "Epoch [94/3000], Loss: 21.3045\n",
      "Epoch [95/3000], Loss: 21.2905\n",
      "Epoch [96/3000], Loss: 21.2765\n",
      "Epoch [97/3000], Loss: 21.2626\n",
      "Epoch [98/3000], Loss: 21.2487\n",
      "Epoch [99/3000], Loss: 21.2348\n",
      "Epoch [100/3000], Loss: 21.2208\n",
      "Epoch [101/3000], Loss: 21.2069\n",
      "Epoch [102/3000], Loss: 21.1930\n",
      "Epoch [103/3000], Loss: 21.1792\n",
      "Epoch [104/3000], Loss: 21.1654\n",
      "Epoch [105/3000], Loss: 21.1516\n",
      "Epoch [106/3000], Loss: 21.1378\n",
      "Epoch [107/3000], Loss: 21.1241\n",
      "Epoch [108/3000], Loss: 21.1103\n",
      "Epoch [109/3000], Loss: 21.0966\n",
      "Epoch [110/3000], Loss: 21.0830\n",
      "Epoch [111/3000], Loss: 21.0693\n",
      "Epoch [112/3000], Loss: 21.0558\n",
      "Epoch [113/3000], Loss: 21.0423\n",
      "Epoch [114/3000], Loss: 21.0288\n",
      "Epoch [115/3000], Loss: 21.0153\n",
      "Epoch [116/3000], Loss: 21.0018\n",
      "Epoch [117/3000], Loss: 20.9883\n",
      "Epoch [118/3000], Loss: 20.9748\n",
      "Epoch [119/3000], Loss: 20.9614\n",
      "Epoch [120/3000], Loss: 20.9479\n",
      "Epoch [121/3000], Loss: 20.9345\n",
      "Epoch [122/3000], Loss: 20.9211\n",
      "Epoch [123/3000], Loss: 20.9078\n",
      "Epoch [124/3000], Loss: 20.8945\n",
      "Epoch [125/3000], Loss: 20.8812\n",
      "Epoch [126/3000], Loss: 20.8679\n",
      "Epoch [127/3000], Loss: 20.8545\n",
      "Epoch [128/3000], Loss: 20.8413\n",
      "Epoch [129/3000], Loss: 20.8281\n",
      "Epoch [130/3000], Loss: 20.8149\n",
      "Epoch [131/3000], Loss: 20.8018\n",
      "Epoch [132/3000], Loss: 20.7886\n",
      "Epoch [133/3000], Loss: 20.7755\n",
      "Epoch [134/3000], Loss: 20.7623\n",
      "Epoch [135/3000], Loss: 20.7493\n",
      "Epoch [136/3000], Loss: 20.7362\n",
      "Epoch [137/3000], Loss: 20.7231\n",
      "Epoch [138/3000], Loss: 20.7101\n",
      "Epoch [139/3000], Loss: 20.6970\n",
      "Epoch [140/3000], Loss: 20.6840\n",
      "Epoch [141/3000], Loss: 20.6709\n",
      "Epoch [142/3000], Loss: 20.6579\n",
      "Epoch [143/3000], Loss: 20.6450\n",
      "Epoch [144/3000], Loss: 20.6320\n",
      "Epoch [145/3000], Loss: 20.6190\n",
      "Epoch [146/3000], Loss: 20.6060\n",
      "Epoch [147/3000], Loss: 20.5931\n",
      "Epoch [148/3000], Loss: 20.5802\n",
      "Epoch [149/3000], Loss: 20.5672\n",
      "Epoch [150/3000], Loss: 20.5543\n",
      "Epoch [151/3000], Loss: 20.5415\n",
      "Epoch [152/3000], Loss: 20.5286\n",
      "Epoch [153/3000], Loss: 20.5158\n",
      "Epoch [154/3000], Loss: 20.5029\n",
      "Epoch [155/3000], Loss: 20.4901\n",
      "Epoch [156/3000], Loss: 20.4773\n",
      "Epoch [157/3000], Loss: 20.4645\n",
      "Epoch [158/3000], Loss: 20.4517\n",
      "Epoch [159/3000], Loss: 20.4389\n",
      "Epoch [160/3000], Loss: 20.4261\n",
      "Epoch [161/3000], Loss: 20.4133\n",
      "Epoch [162/3000], Loss: 20.4004\n",
      "Epoch [163/3000], Loss: 20.3876\n",
      "Epoch [164/3000], Loss: 20.3748\n",
      "Epoch [165/3000], Loss: 20.3619\n",
      "Epoch [166/3000], Loss: 20.3491\n",
      "Epoch [167/3000], Loss: 20.3364\n",
      "Epoch [168/3000], Loss: 20.3236\n",
      "Epoch [169/3000], Loss: 20.3108\n",
      "Epoch [170/3000], Loss: 20.2981\n",
      "Epoch [171/3000], Loss: 20.2853\n",
      "Epoch [172/3000], Loss: 20.2726\n",
      "Epoch [173/3000], Loss: 20.2599\n",
      "Epoch [174/3000], Loss: 20.2472\n",
      "Epoch [175/3000], Loss: 20.2345\n",
      "Epoch [176/3000], Loss: 20.2219\n",
      "Epoch [177/3000], Loss: 20.2092\n",
      "Epoch [178/3000], Loss: 20.1966\n",
      "Epoch [179/3000], Loss: 20.1839\n",
      "Epoch [180/3000], Loss: 20.1712\n",
      "Epoch [181/3000], Loss: 20.1585\n",
      "Epoch [182/3000], Loss: 20.1459\n",
      "Epoch [183/3000], Loss: 20.1332\n",
      "Epoch [184/3000], Loss: 20.1205\n",
      "Epoch [185/3000], Loss: 20.1078\n",
      "Epoch [186/3000], Loss: 20.0951\n",
      "Epoch [187/3000], Loss: 20.0825\n",
      "Epoch [188/3000], Loss: 20.0698\n",
      "Epoch [189/3000], Loss: 20.0571\n",
      "Epoch [190/3000], Loss: 20.0443\n",
      "Epoch [191/3000], Loss: 20.0316\n",
      "Epoch [192/3000], Loss: 20.0189\n",
      "Epoch [193/3000], Loss: 20.0061\n",
      "Epoch [194/3000], Loss: 19.9934\n",
      "Epoch [195/3000], Loss: 19.9807\n",
      "Epoch [196/3000], Loss: 19.9679\n",
      "Epoch [197/3000], Loss: 19.9551\n",
      "Epoch [198/3000], Loss: 19.9423\n",
      "Epoch [199/3000], Loss: 19.9295\n",
      "Epoch [200/3000], Loss: 19.9168\n",
      "Epoch [201/3000], Loss: 19.9040\n",
      "Epoch [202/3000], Loss: 19.8912\n",
      "Epoch [203/3000], Loss: 19.8785\n",
      "Epoch [204/3000], Loss: 19.8657\n",
      "Epoch [205/3000], Loss: 19.8529\n",
      "Epoch [206/3000], Loss: 19.8402\n",
      "Epoch [207/3000], Loss: 19.8274\n",
      "Epoch [208/3000], Loss: 19.8147\n",
      "Epoch [209/3000], Loss: 19.8019\n",
      "Epoch [210/3000], Loss: 19.7891\n",
      "Epoch [211/3000], Loss: 19.7763\n",
      "Epoch [212/3000], Loss: 19.7635\n",
      "Epoch [213/3000], Loss: 19.7507\n",
      "Epoch [214/3000], Loss: 19.7379\n",
      "Epoch [215/3000], Loss: 19.7251\n",
      "Epoch [216/3000], Loss: 19.7123\n",
      "Epoch [217/3000], Loss: 19.6995\n",
      "Epoch [218/3000], Loss: 19.6867\n",
      "Epoch [219/3000], Loss: 19.6739\n",
      "Epoch [220/3000], Loss: 19.6611\n",
      "Epoch [221/3000], Loss: 19.6483\n",
      "Epoch [222/3000], Loss: 19.6354\n",
      "Epoch [223/3000], Loss: 19.6226\n",
      "Epoch [224/3000], Loss: 19.6097\n",
      "Epoch [225/3000], Loss: 19.5969\n",
      "Epoch [226/3000], Loss: 19.5840\n",
      "Epoch [227/3000], Loss: 19.5711\n",
      "Epoch [228/3000], Loss: 19.5582\n",
      "Epoch [229/3000], Loss: 19.5453\n",
      "Epoch [230/3000], Loss: 19.5324\n",
      "Epoch [231/3000], Loss: 19.5194\n",
      "Epoch [232/3000], Loss: 19.5065\n",
      "Epoch [233/3000], Loss: 19.4936\n",
      "Epoch [234/3000], Loss: 19.4807\n",
      "Epoch [235/3000], Loss: 19.4677\n",
      "Epoch [236/3000], Loss: 19.4547\n",
      "Epoch [237/3000], Loss: 19.4417\n",
      "Epoch [238/3000], Loss: 19.4286\n",
      "Epoch [239/3000], Loss: 19.4155\n",
      "Epoch [240/3000], Loss: 19.4025\n",
      "Epoch [241/3000], Loss: 19.3894\n",
      "Epoch [242/3000], Loss: 19.3763\n",
      "Epoch [243/3000], Loss: 19.3632\n",
      "Epoch [244/3000], Loss: 19.3501\n",
      "Epoch [245/3000], Loss: 19.3369\n",
      "Epoch [246/3000], Loss: 19.3237\n",
      "Epoch [247/3000], Loss: 19.3105\n",
      "Epoch [248/3000], Loss: 19.2973\n",
      "Epoch [249/3000], Loss: 19.2841\n",
      "Epoch [250/3000], Loss: 19.2709\n",
      "Epoch [251/3000], Loss: 19.2577\n",
      "Epoch [252/3000], Loss: 19.2444\n",
      "Epoch [253/3000], Loss: 19.2311\n",
      "Epoch [254/3000], Loss: 19.2178\n",
      "Epoch [255/3000], Loss: 19.2045\n",
      "Epoch [256/3000], Loss: 19.1912\n",
      "Epoch [257/3000], Loss: 19.1779\n",
      "Epoch [258/3000], Loss: 19.1646\n",
      "Epoch [259/3000], Loss: 19.1513\n",
      "Epoch [260/3000], Loss: 19.1379\n",
      "Epoch [261/3000], Loss: 19.1245\n",
      "Epoch [262/3000], Loss: 19.1111\n",
      "Epoch [263/3000], Loss: 19.0976\n",
      "Epoch [264/3000], Loss: 19.0842\n",
      "Epoch [265/3000], Loss: 19.0707\n",
      "Epoch [266/3000], Loss: 19.0571\n",
      "Epoch [267/3000], Loss: 19.0435\n",
      "Epoch [268/3000], Loss: 19.0300\n",
      "Epoch [269/3000], Loss: 19.0164\n",
      "Epoch [270/3000], Loss: 19.0027\n",
      "Epoch [271/3000], Loss: 18.9890\n",
      "Epoch [272/3000], Loss: 18.9754\n",
      "Epoch [273/3000], Loss: 18.9617\n",
      "Epoch [274/3000], Loss: 18.9479\n",
      "Epoch [275/3000], Loss: 18.9341\n",
      "Epoch [276/3000], Loss: 18.9203\n",
      "Epoch [277/3000], Loss: 18.9065\n",
      "Epoch [278/3000], Loss: 18.8926\n",
      "Epoch [279/3000], Loss: 18.8787\n",
      "Epoch [280/3000], Loss: 18.8648\n",
      "Epoch [281/3000], Loss: 18.8508\n",
      "Epoch [282/3000], Loss: 18.8368\n",
      "Epoch [283/3000], Loss: 18.8229\n",
      "Epoch [284/3000], Loss: 18.8089\n",
      "Epoch [285/3000], Loss: 18.7948\n",
      "Epoch [286/3000], Loss: 18.7808\n",
      "Epoch [287/3000], Loss: 18.7667\n",
      "Epoch [288/3000], Loss: 18.7525\n",
      "Epoch [289/3000], Loss: 18.7383\n",
      "Epoch [290/3000], Loss: 18.7241\n",
      "Epoch [291/3000], Loss: 18.7098\n",
      "Epoch [292/3000], Loss: 18.6954\n",
      "Epoch [293/3000], Loss: 18.6810\n",
      "Epoch [294/3000], Loss: 18.6666\n",
      "Epoch [295/3000], Loss: 18.6522\n",
      "Epoch [296/3000], Loss: 18.6377\n",
      "Epoch [297/3000], Loss: 18.6232\n",
      "Epoch [298/3000], Loss: 18.6087\n",
      "Epoch [299/3000], Loss: 18.5941\n",
      "Epoch [300/3000], Loss: 18.5795\n",
      "Epoch [301/3000], Loss: 18.5649\n",
      "Epoch [302/3000], Loss: 18.5503\n",
      "Epoch [303/3000], Loss: 18.5357\n",
      "Epoch [304/3000], Loss: 18.5210\n",
      "Epoch [305/3000], Loss: 18.5063\n",
      "Epoch [306/3000], Loss: 18.4916\n",
      "Epoch [307/3000], Loss: 18.4769\n",
      "Epoch [308/3000], Loss: 18.4620\n",
      "Epoch [309/3000], Loss: 18.4472\n",
      "Epoch [310/3000], Loss: 18.4323\n",
      "Epoch [311/3000], Loss: 18.4175\n",
      "Epoch [312/3000], Loss: 18.4025\n",
      "Epoch [313/3000], Loss: 18.3876\n",
      "Epoch [314/3000], Loss: 18.3726\n",
      "Epoch [315/3000], Loss: 18.3576\n",
      "Epoch [316/3000], Loss: 18.3427\n",
      "Epoch [317/3000], Loss: 18.3277\n",
      "Epoch [318/3000], Loss: 18.3127\n",
      "Epoch [319/3000], Loss: 18.2977\n",
      "Epoch [320/3000], Loss: 18.2826\n",
      "Epoch [321/3000], Loss: 18.2675\n",
      "Epoch [322/3000], Loss: 18.2524\n",
      "Epoch [323/3000], Loss: 18.2373\n",
      "Epoch [324/3000], Loss: 18.2222\n",
      "Epoch [325/3000], Loss: 18.2070\n",
      "Epoch [326/3000], Loss: 18.1919\n",
      "Epoch [327/3000], Loss: 18.1767\n",
      "Epoch [328/3000], Loss: 18.1615\n",
      "Epoch [329/3000], Loss: 18.1463\n",
      "Epoch [330/3000], Loss: 18.1310\n",
      "Epoch [331/3000], Loss: 18.1158\n",
      "Epoch [332/3000], Loss: 18.1005\n",
      "Epoch [333/3000], Loss: 18.0853\n",
      "Epoch [334/3000], Loss: 18.0700\n",
      "Epoch [335/3000], Loss: 18.0547\n",
      "Epoch [336/3000], Loss: 18.0394\n",
      "Epoch [337/3000], Loss: 18.0241\n",
      "Epoch [338/3000], Loss: 18.0088\n",
      "Epoch [339/3000], Loss: 17.9934\n",
      "Epoch [340/3000], Loss: 17.9781\n",
      "Epoch [341/3000], Loss: 17.9628\n",
      "Epoch [342/3000], Loss: 17.9474\n",
      "Epoch [343/3000], Loss: 17.9320\n",
      "Epoch [344/3000], Loss: 17.9166\n",
      "Epoch [345/3000], Loss: 17.9012\n",
      "Epoch [346/3000], Loss: 17.8857\n",
      "Epoch [347/3000], Loss: 17.8703\n",
      "Epoch [348/3000], Loss: 17.8549\n",
      "Epoch [349/3000], Loss: 17.8394\n",
      "Epoch [350/3000], Loss: 17.8240\n",
      "Epoch [351/3000], Loss: 17.8085\n",
      "Epoch [352/3000], Loss: 17.7930\n",
      "Epoch [353/3000], Loss: 17.7776\n",
      "Epoch [354/3000], Loss: 17.7621\n",
      "Epoch [355/3000], Loss: 17.7467\n",
      "Epoch [356/3000], Loss: 17.7312\n",
      "Epoch [357/3000], Loss: 17.7157\n",
      "Epoch [358/3000], Loss: 17.7002\n",
      "Epoch [359/3000], Loss: 17.6847\n",
      "Epoch [360/3000], Loss: 17.6693\n",
      "Epoch [361/3000], Loss: 17.6538\n",
      "Epoch [362/3000], Loss: 17.6384\n",
      "Epoch [363/3000], Loss: 17.6229\n",
      "Epoch [364/3000], Loss: 17.6074\n",
      "Epoch [365/3000], Loss: 17.5919\n",
      "Epoch [366/3000], Loss: 17.5764\n",
      "Epoch [367/3000], Loss: 17.5609\n",
      "Epoch [368/3000], Loss: 17.5454\n",
      "Epoch [369/3000], Loss: 17.5300\n",
      "Epoch [370/3000], Loss: 17.5145\n",
      "Epoch [371/3000], Loss: 17.4990\n",
      "Epoch [372/3000], Loss: 17.4835\n",
      "Epoch [373/3000], Loss: 17.4680\n",
      "Epoch [374/3000], Loss: 17.4526\n",
      "Epoch [375/3000], Loss: 17.4371\n",
      "Epoch [376/3000], Loss: 17.4217\n",
      "Epoch [377/3000], Loss: 17.4063\n",
      "Epoch [378/3000], Loss: 17.3908\n",
      "Epoch [379/3000], Loss: 17.3754\n",
      "Epoch [380/3000], Loss: 17.3599\n",
      "Epoch [381/3000], Loss: 17.3445\n",
      "Epoch [382/3000], Loss: 17.3290\n",
      "Epoch [383/3000], Loss: 17.3135\n",
      "Epoch [384/3000], Loss: 17.2980\n",
      "Epoch [385/3000], Loss: 17.2825\n",
      "Epoch [386/3000], Loss: 17.2670\n",
      "Epoch [387/3000], Loss: 17.2515\n",
      "Epoch [388/3000], Loss: 17.2361\n",
      "Epoch [389/3000], Loss: 17.2207\n",
      "Epoch [390/3000], Loss: 17.2052\n",
      "Epoch [391/3000], Loss: 17.1898\n",
      "Epoch [392/3000], Loss: 17.1743\n",
      "Epoch [393/3000], Loss: 17.1587\n",
      "Epoch [394/3000], Loss: 17.1431\n",
      "Epoch [395/3000], Loss: 17.1275\n",
      "Epoch [396/3000], Loss: 17.1120\n",
      "Epoch [397/3000], Loss: 17.0965\n",
      "Epoch [398/3000], Loss: 17.0809\n",
      "Epoch [399/3000], Loss: 17.0653\n",
      "Epoch [400/3000], Loss: 17.0497\n",
      "Epoch [401/3000], Loss: 17.0340\n",
      "Epoch [402/3000], Loss: 17.0184\n",
      "Epoch [403/3000], Loss: 17.0028\n",
      "Epoch [404/3000], Loss: 16.9872\n",
      "Epoch [405/3000], Loss: 16.9716\n",
      "Epoch [406/3000], Loss: 16.9560\n",
      "Epoch [407/3000], Loss: 16.9404\n",
      "Epoch [408/3000], Loss: 16.9248\n",
      "Epoch [409/3000], Loss: 16.9093\n",
      "Epoch [410/3000], Loss: 16.8937\n",
      "Epoch [411/3000], Loss: 16.8781\n",
      "Epoch [412/3000], Loss: 16.8626\n",
      "Epoch [413/3000], Loss: 16.8470\n",
      "Epoch [414/3000], Loss: 16.8314\n",
      "Epoch [415/3000], Loss: 16.8158\n",
      "Epoch [416/3000], Loss: 16.8002\n",
      "Epoch [417/3000], Loss: 16.7846\n",
      "Epoch [418/3000], Loss: 16.7690\n",
      "Epoch [419/3000], Loss: 16.7534\n",
      "Epoch [420/3000], Loss: 16.7378\n",
      "Epoch [421/3000], Loss: 16.7222\n",
      "Epoch [422/3000], Loss: 16.7066\n",
      "Epoch [423/3000], Loss: 16.6909\n",
      "Epoch [424/3000], Loss: 16.6753\n",
      "Epoch [425/3000], Loss: 16.6597\n",
      "Epoch [426/3000], Loss: 16.6440\n",
      "Epoch [427/3000], Loss: 16.6284\n",
      "Epoch [428/3000], Loss: 16.6127\n",
      "Epoch [429/3000], Loss: 16.5971\n",
      "Epoch [430/3000], Loss: 16.5815\n",
      "Epoch [431/3000], Loss: 16.5658\n",
      "Epoch [432/3000], Loss: 16.5502\n",
      "Epoch [433/3000], Loss: 16.5346\n",
      "Epoch [434/3000], Loss: 16.5190\n",
      "Epoch [435/3000], Loss: 16.5033\n",
      "Epoch [436/3000], Loss: 16.4877\n",
      "Epoch [437/3000], Loss: 16.4721\n",
      "Epoch [438/3000], Loss: 16.4565\n",
      "Epoch [439/3000], Loss: 16.4408\n",
      "Epoch [440/3000], Loss: 16.4252\n",
      "Epoch [441/3000], Loss: 16.4096\n",
      "Epoch [442/3000], Loss: 16.3941\n",
      "Epoch [443/3000], Loss: 16.3784\n",
      "Epoch [444/3000], Loss: 16.3628\n",
      "Epoch [445/3000], Loss: 16.3472\n",
      "Epoch [446/3000], Loss: 16.3316\n",
      "Epoch [447/3000], Loss: 16.3160\n",
      "Epoch [448/3000], Loss: 16.3004\n",
      "Epoch [449/3000], Loss: 16.2847\n",
      "Epoch [450/3000], Loss: 16.2691\n",
      "Epoch [451/3000], Loss: 16.2535\n",
      "Epoch [452/3000], Loss: 16.2379\n",
      "Epoch [453/3000], Loss: 16.2222\n",
      "Epoch [454/3000], Loss: 16.2064\n",
      "Epoch [455/3000], Loss: 16.1906\n",
      "Epoch [456/3000], Loss: 16.1747\n",
      "Epoch [457/3000], Loss: 16.1589\n",
      "Epoch [458/3000], Loss: 16.1432\n",
      "Epoch [459/3000], Loss: 16.1274\n",
      "Epoch [460/3000], Loss: 16.1117\n",
      "Epoch [461/3000], Loss: 16.0959\n",
      "Epoch [462/3000], Loss: 16.0801\n",
      "Epoch [463/3000], Loss: 16.0643\n",
      "Epoch [464/3000], Loss: 16.0485\n",
      "Epoch [465/3000], Loss: 16.0327\n",
      "Epoch [466/3000], Loss: 16.0170\n",
      "Epoch [467/3000], Loss: 16.0012\n",
      "Epoch [468/3000], Loss: 15.9855\n",
      "Epoch [469/3000], Loss: 15.9699\n",
      "Epoch [470/3000], Loss: 15.9542\n",
      "Epoch [471/3000], Loss: 15.9385\n",
      "Epoch [472/3000], Loss: 15.9228\n",
      "Epoch [473/3000], Loss: 15.9072\n",
      "Epoch [474/3000], Loss: 15.8915\n",
      "Epoch [475/3000], Loss: 15.8758\n",
      "Epoch [476/3000], Loss: 15.8602\n",
      "Epoch [477/3000], Loss: 15.8445\n",
      "Epoch [478/3000], Loss: 15.8289\n",
      "Epoch [479/3000], Loss: 15.8133\n",
      "Epoch [480/3000], Loss: 15.7976\n",
      "Epoch [481/3000], Loss: 15.7821\n",
      "Epoch [482/3000], Loss: 15.7665\n",
      "Epoch [483/3000], Loss: 15.7509\n",
      "Epoch [484/3000], Loss: 15.7354\n",
      "Epoch [485/3000], Loss: 15.7198\n",
      "Epoch [486/3000], Loss: 15.7043\n",
      "Epoch [487/3000], Loss: 15.6889\n",
      "Epoch [488/3000], Loss: 15.6734\n",
      "Epoch [489/3000], Loss: 15.6580\n",
      "Epoch [490/3000], Loss: 15.6425\n",
      "Epoch [491/3000], Loss: 15.6271\n",
      "Epoch [492/3000], Loss: 15.6117\n",
      "Epoch [493/3000], Loss: 15.5963\n",
      "Epoch [494/3000], Loss: 15.5809\n",
      "Epoch [495/3000], Loss: 15.5654\n",
      "Epoch [496/3000], Loss: 15.5500\n",
      "Epoch [497/3000], Loss: 15.5346\n",
      "Epoch [498/3000], Loss: 15.5192\n",
      "Epoch [499/3000], Loss: 15.5038\n",
      "Epoch [500/3000], Loss: 15.4885\n",
      "Epoch [501/3000], Loss: 15.4732\n",
      "Epoch [502/3000], Loss: 15.4579\n",
      "Epoch [503/3000], Loss: 15.4426\n",
      "Epoch [504/3000], Loss: 15.4273\n",
      "Epoch [505/3000], Loss: 15.4121\n",
      "Epoch [506/3000], Loss: 15.3968\n",
      "Epoch [507/3000], Loss: 15.3815\n",
      "Epoch [508/3000], Loss: 15.3662\n",
      "Epoch [509/3000], Loss: 15.3509\n",
      "Epoch [510/3000], Loss: 15.3357\n",
      "Epoch [511/3000], Loss: 15.3205\n",
      "Epoch [512/3000], Loss: 15.3054\n",
      "Epoch [513/3000], Loss: 15.2903\n",
      "Epoch [514/3000], Loss: 15.2752\n",
      "Epoch [515/3000], Loss: 15.2601\n",
      "Epoch [516/3000], Loss: 15.2450\n",
      "Epoch [517/3000], Loss: 15.2299\n",
      "Epoch [518/3000], Loss: 15.2149\n",
      "Epoch [519/3000], Loss: 15.1999\n",
      "Epoch [520/3000], Loss: 15.1849\n",
      "Epoch [521/3000], Loss: 15.1700\n",
      "Epoch [522/3000], Loss: 15.1550\n",
      "Epoch [523/3000], Loss: 15.1401\n",
      "Epoch [524/3000], Loss: 15.1252\n",
      "Epoch [525/3000], Loss: 15.1104\n",
      "Epoch [526/3000], Loss: 15.0956\n",
      "Epoch [527/3000], Loss: 15.0807\n",
      "Epoch [528/3000], Loss: 15.0659\n",
      "Epoch [529/3000], Loss: 15.0511\n",
      "Epoch [530/3000], Loss: 15.0363\n",
      "Epoch [531/3000], Loss: 15.0215\n",
      "Epoch [532/3000], Loss: 15.0068\n",
      "Epoch [533/3000], Loss: 14.9921\n",
      "Epoch [534/3000], Loss: 14.9774\n",
      "Epoch [535/3000], Loss: 14.9626\n",
      "Epoch [536/3000], Loss: 14.9479\n",
      "Epoch [537/3000], Loss: 14.9333\n",
      "Epoch [538/3000], Loss: 14.9186\n",
      "Epoch [539/3000], Loss: 14.9040\n",
      "Epoch [540/3000], Loss: 14.8894\n",
      "Epoch [541/3000], Loss: 14.8748\n",
      "Epoch [542/3000], Loss: 14.8603\n",
      "Epoch [543/3000], Loss: 14.8458\n",
      "Epoch [544/3000], Loss: 14.8313\n",
      "Epoch [545/3000], Loss: 14.8168\n",
      "Epoch [546/3000], Loss: 14.8024\n",
      "Epoch [547/3000], Loss: 14.7880\n",
      "Epoch [548/3000], Loss: 14.7736\n",
      "Epoch [549/3000], Loss: 14.7592\n",
      "Epoch [550/3000], Loss: 14.7449\n",
      "Epoch [551/3000], Loss: 14.7305\n",
      "Epoch [552/3000], Loss: 14.7163\n",
      "Epoch [553/3000], Loss: 14.7020\n",
      "Epoch [554/3000], Loss: 14.6877\n",
      "Epoch [555/3000], Loss: 14.6735\n",
      "Epoch [556/3000], Loss: 14.6593\n",
      "Epoch [557/3000], Loss: 14.6451\n",
      "Epoch [558/3000], Loss: 14.6310\n",
      "Epoch [559/3000], Loss: 14.6168\n",
      "Epoch [560/3000], Loss: 14.6027\n",
      "Epoch [561/3000], Loss: 14.5886\n",
      "Epoch [562/3000], Loss: 14.5745\n",
      "Epoch [563/3000], Loss: 14.5605\n",
      "Epoch [564/3000], Loss: 14.5465\n",
      "Epoch [565/3000], Loss: 14.5325\n",
      "Epoch [566/3000], Loss: 14.5185\n",
      "Epoch [567/3000], Loss: 14.5046\n",
      "Epoch [568/3000], Loss: 14.4907\n",
      "Epoch [569/3000], Loss: 14.4768\n",
      "Epoch [570/3000], Loss: 14.4629\n",
      "Epoch [571/3000], Loss: 14.4491\n",
      "Epoch [572/3000], Loss: 14.4353\n",
      "Epoch [573/3000], Loss: 14.4215\n",
      "Epoch [574/3000], Loss: 14.4077\n",
      "Epoch [575/3000], Loss: 14.3939\n",
      "Epoch [576/3000], Loss: 14.3802\n",
      "Epoch [577/3000], Loss: 14.3665\n",
      "Epoch [578/3000], Loss: 14.3528\n",
      "Epoch [579/3000], Loss: 14.3391\n",
      "Epoch [580/3000], Loss: 14.3254\n",
      "Epoch [581/3000], Loss: 14.3118\n",
      "Epoch [582/3000], Loss: 14.2981\n",
      "Epoch [583/3000], Loss: 14.2845\n",
      "Epoch [584/3000], Loss: 14.2708\n",
      "Epoch [585/3000], Loss: 14.2572\n",
      "Epoch [586/3000], Loss: 14.2436\n",
      "Epoch [587/3000], Loss: 14.2301\n",
      "Epoch [588/3000], Loss: 14.2165\n",
      "Epoch [589/3000], Loss: 14.2030\n",
      "Epoch [590/3000], Loss: 14.1894\n",
      "Epoch [591/3000], Loss: 14.1759\n",
      "Epoch [592/3000], Loss: 14.1625\n",
      "Epoch [593/3000], Loss: 14.1490\n",
      "Epoch [594/3000], Loss: 14.1356\n",
      "Epoch [595/3000], Loss: 14.1222\n",
      "Epoch [596/3000], Loss: 14.1087\n",
      "Epoch [597/3000], Loss: 14.0953\n",
      "Epoch [598/3000], Loss: 14.0820\n",
      "Epoch [599/3000], Loss: 14.0686\n",
      "Epoch [600/3000], Loss: 14.0553\n",
      "Epoch [601/3000], Loss: 14.0420\n",
      "Epoch [602/3000], Loss: 14.0287\n",
      "Epoch [603/3000], Loss: 14.0154\n",
      "Epoch [604/3000], Loss: 14.0022\n",
      "Epoch [605/3000], Loss: 13.9889\n",
      "Epoch [606/3000], Loss: 13.9756\n",
      "Epoch [607/3000], Loss: 13.9624\n",
      "Epoch [608/3000], Loss: 13.9491\n",
      "Epoch [609/3000], Loss: 13.9359\n",
      "Epoch [610/3000], Loss: 13.9228\n",
      "Epoch [611/3000], Loss: 13.9096\n",
      "Epoch [612/3000], Loss: 13.8965\n",
      "Epoch [613/3000], Loss: 13.8834\n",
      "Epoch [614/3000], Loss: 13.8703\n",
      "Epoch [615/3000], Loss: 13.8572\n",
      "Epoch [616/3000], Loss: 13.8442\n",
      "Epoch [617/3000], Loss: 13.8311\n",
      "Epoch [618/3000], Loss: 13.8181\n",
      "Epoch [619/3000], Loss: 13.8050\n",
      "Epoch [620/3000], Loss: 13.7921\n",
      "Epoch [621/3000], Loss: 13.7791\n",
      "Epoch [622/3000], Loss: 13.7661\n",
      "Epoch [623/3000], Loss: 13.7532\n",
      "Epoch [624/3000], Loss: 13.7402\n",
      "Epoch [625/3000], Loss: 13.7273\n",
      "Epoch [626/3000], Loss: 13.7144\n",
      "Epoch [627/3000], Loss: 13.7015\n",
      "Epoch [628/3000], Loss: 13.6886\n",
      "Epoch [629/3000], Loss: 13.6758\n",
      "Epoch [630/3000], Loss: 13.6629\n",
      "Epoch [631/3000], Loss: 13.6501\n",
      "Epoch [632/3000], Loss: 13.6373\n",
      "Epoch [633/3000], Loss: 13.6246\n",
      "Epoch [634/3000], Loss: 13.6119\n",
      "Epoch [635/3000], Loss: 13.5991\n",
      "Epoch [636/3000], Loss: 13.5864\n",
      "Epoch [637/3000], Loss: 13.5738\n",
      "Epoch [638/3000], Loss: 13.5610\n",
      "Epoch [639/3000], Loss: 13.5483\n",
      "Epoch [640/3000], Loss: 13.5356\n",
      "Epoch [641/3000], Loss: 13.5230\n",
      "Epoch [642/3000], Loss: 13.5104\n",
      "Epoch [643/3000], Loss: 13.4978\n",
      "Epoch [644/3000], Loss: 13.4852\n",
      "Epoch [645/3000], Loss: 13.4727\n",
      "Epoch [646/3000], Loss: 13.4602\n",
      "Epoch [647/3000], Loss: 13.4476\n",
      "Epoch [648/3000], Loss: 13.4351\n",
      "Epoch [649/3000], Loss: 13.4226\n",
      "Epoch [650/3000], Loss: 13.4101\n",
      "Epoch [651/3000], Loss: 13.3976\n",
      "Epoch [652/3000], Loss: 13.3852\n",
      "Epoch [653/3000], Loss: 13.3727\n",
      "Epoch [654/3000], Loss: 13.3603\n",
      "Epoch [655/3000], Loss: 13.3479\n",
      "Epoch [656/3000], Loss: 13.3355\n",
      "Epoch [657/3000], Loss: 13.3232\n",
      "Epoch [658/3000], Loss: 13.3109\n",
      "Epoch [659/3000], Loss: 13.2985\n",
      "Epoch [660/3000], Loss: 13.2862\n",
      "Epoch [661/3000], Loss: 13.2739\n",
      "Epoch [662/3000], Loss: 13.2616\n",
      "Epoch [663/3000], Loss: 13.2493\n",
      "Epoch [664/3000], Loss: 13.2370\n",
      "Epoch [665/3000], Loss: 13.2248\n",
      "Epoch [666/3000], Loss: 13.2125\n",
      "Epoch [667/3000], Loss: 13.2003\n",
      "Epoch [668/3000], Loss: 13.1881\n",
      "Epoch [669/3000], Loss: 13.1759\n",
      "Epoch [670/3000], Loss: 13.1638\n",
      "Epoch [671/3000], Loss: 13.1516\n",
      "Epoch [672/3000], Loss: 13.1394\n",
      "Epoch [673/3000], Loss: 13.1273\n",
      "Epoch [674/3000], Loss: 13.1151\n",
      "Epoch [675/3000], Loss: 13.1030\n",
      "Epoch [676/3000], Loss: 13.0909\n",
      "Epoch [677/3000], Loss: 13.0788\n",
      "Epoch [678/3000], Loss: 13.0667\n",
      "Epoch [679/3000], Loss: 13.0546\n",
      "Epoch [680/3000], Loss: 13.0426\n",
      "Epoch [681/3000], Loss: 13.0305\n",
      "Epoch [682/3000], Loss: 13.0185\n",
      "Epoch [683/3000], Loss: 13.0064\n",
      "Epoch [684/3000], Loss: 12.9944\n",
      "Epoch [685/3000], Loss: 12.9824\n",
      "Epoch [686/3000], Loss: 12.9704\n",
      "Epoch [687/3000], Loss: 12.9585\n",
      "Epoch [688/3000], Loss: 12.9465\n",
      "Epoch [689/3000], Loss: 12.9346\n",
      "Epoch [690/3000], Loss: 12.9227\n",
      "Epoch [691/3000], Loss: 12.9108\n",
      "Epoch [692/3000], Loss: 12.8989\n",
      "Epoch [693/3000], Loss: 12.8870\n",
      "Epoch [694/3000], Loss: 12.8751\n",
      "Epoch [695/3000], Loss: 12.8633\n",
      "Epoch [696/3000], Loss: 12.8515\n",
      "Epoch [697/3000], Loss: 12.8397\n",
      "Epoch [698/3000], Loss: 12.8279\n",
      "Epoch [699/3000], Loss: 12.8161\n",
      "Epoch [700/3000], Loss: 12.8043\n",
      "Epoch [701/3000], Loss: 12.7926\n",
      "Epoch [702/3000], Loss: 12.7808\n",
      "Epoch [703/3000], Loss: 12.7691\n",
      "Epoch [704/3000], Loss: 12.7574\n",
      "Epoch [705/3000], Loss: 12.7456\n",
      "Epoch [706/3000], Loss: 12.7339\n",
      "Epoch [707/3000], Loss: 12.7222\n",
      "Epoch [708/3000], Loss: 12.7106\n",
      "Epoch [709/3000], Loss: 12.6989\n",
      "Epoch [710/3000], Loss: 12.6873\n",
      "Epoch [711/3000], Loss: 12.6757\n",
      "Epoch [712/3000], Loss: 12.6641\n",
      "Epoch [713/3000], Loss: 12.6526\n",
      "Epoch [714/3000], Loss: 12.6410\n",
      "Epoch [715/3000], Loss: 12.6296\n",
      "Epoch [716/3000], Loss: 12.6181\n",
      "Epoch [717/3000], Loss: 12.6067\n",
      "Epoch [718/3000], Loss: 12.5953\n",
      "Epoch [719/3000], Loss: 12.5838\n",
      "Epoch [720/3000], Loss: 12.5722\n",
      "Epoch [721/3000], Loss: 12.5607\n",
      "Epoch [722/3000], Loss: 12.5493\n",
      "Epoch [723/3000], Loss: 12.5380\n",
      "Epoch [724/3000], Loss: 12.5266\n",
      "Epoch [725/3000], Loss: 12.5153\n",
      "Epoch [726/3000], Loss: 12.5040\n",
      "Epoch [727/3000], Loss: 12.4927\n",
      "Epoch [728/3000], Loss: 12.4813\n",
      "Epoch [729/3000], Loss: 12.4699\n",
      "Epoch [730/3000], Loss: 12.4585\n",
      "Epoch [731/3000], Loss: 12.4471\n",
      "Epoch [732/3000], Loss: 12.4358\n",
      "Epoch [733/3000], Loss: 12.4245\n",
      "Epoch [734/3000], Loss: 12.4131\n",
      "Epoch [735/3000], Loss: 12.4017\n",
      "Epoch [736/3000], Loss: 12.3903\n",
      "Epoch [737/3000], Loss: 12.3789\n",
      "Epoch [738/3000], Loss: 12.3675\n",
      "Epoch [739/3000], Loss: 12.3561\n",
      "Epoch [740/3000], Loss: 12.3448\n",
      "Epoch [741/3000], Loss: 12.3334\n",
      "Epoch [742/3000], Loss: 12.3219\n",
      "Epoch [743/3000], Loss: 12.3105\n",
      "Epoch [744/3000], Loss: 12.2990\n",
      "Epoch [745/3000], Loss: 12.2875\n",
      "Epoch [746/3000], Loss: 12.2761\n",
      "Epoch [747/3000], Loss: 12.2646\n",
      "Epoch [748/3000], Loss: 12.2531\n",
      "Epoch [749/3000], Loss: 12.2416\n",
      "Epoch [750/3000], Loss: 12.2301\n",
      "Epoch [751/3000], Loss: 12.2187\n",
      "Epoch [752/3000], Loss: 12.2071\n",
      "Epoch [753/3000], Loss: 12.1956\n",
      "Epoch [754/3000], Loss: 12.1841\n",
      "Epoch [755/3000], Loss: 12.1725\n",
      "Epoch [756/3000], Loss: 12.1608\n",
      "Epoch [757/3000], Loss: 12.1491\n",
      "Epoch [758/3000], Loss: 12.1374\n",
      "Epoch [759/3000], Loss: 12.1257\n",
      "Epoch [760/3000], Loss: 12.1139\n",
      "Epoch [761/3000], Loss: 12.1021\n",
      "Epoch [762/3000], Loss: 12.0903\n",
      "Epoch [763/3000], Loss: 12.0784\n",
      "Epoch [764/3000], Loss: 12.0665\n",
      "Epoch [765/3000], Loss: 12.0546\n",
      "Epoch [766/3000], Loss: 12.0428\n",
      "Epoch [767/3000], Loss: 12.0310\n",
      "Epoch [768/3000], Loss: 12.0191\n",
      "Epoch [769/3000], Loss: 12.0072\n",
      "Epoch [770/3000], Loss: 11.9953\n",
      "Epoch [771/3000], Loss: 11.9834\n",
      "Epoch [772/3000], Loss: 11.9715\n",
      "Epoch [773/3000], Loss: 11.9596\n",
      "Epoch [774/3000], Loss: 11.9477\n",
      "Epoch [775/3000], Loss: 11.9359\n",
      "Epoch [776/3000], Loss: 11.9240\n",
      "Epoch [777/3000], Loss: 11.9122\n",
      "Epoch [778/3000], Loss: 11.9003\n",
      "Epoch [779/3000], Loss: 11.8885\n",
      "Epoch [780/3000], Loss: 11.8767\n",
      "Epoch [781/3000], Loss: 11.8649\n",
      "Epoch [782/3000], Loss: 11.8530\n",
      "Epoch [783/3000], Loss: 11.8412\n",
      "Epoch [784/3000], Loss: 11.8294\n",
      "Epoch [785/3000], Loss: 11.8175\n",
      "Epoch [786/3000], Loss: 11.8057\n",
      "Epoch [787/3000], Loss: 11.7938\n",
      "Epoch [788/3000], Loss: 11.7820\n",
      "Epoch [789/3000], Loss: 11.7702\n",
      "Epoch [790/3000], Loss: 11.7583\n",
      "Epoch [791/3000], Loss: 11.7465\n",
      "Epoch [792/3000], Loss: 11.7348\n",
      "Epoch [793/3000], Loss: 11.7230\n",
      "Epoch [794/3000], Loss: 11.7112\n",
      "Epoch [795/3000], Loss: 11.6994\n",
      "Epoch [796/3000], Loss: 11.6877\n",
      "Epoch [797/3000], Loss: 11.6759\n",
      "Epoch [798/3000], Loss: 11.6641\n",
      "Epoch [799/3000], Loss: 11.6524\n",
      "Epoch [800/3000], Loss: 11.6406\n",
      "Epoch [801/3000], Loss: 11.6288\n",
      "Epoch [802/3000], Loss: 11.6170\n",
      "Epoch [803/3000], Loss: 11.6053\n",
      "Epoch [804/3000], Loss: 11.5936\n",
      "Epoch [805/3000], Loss: 11.5819\n",
      "Epoch [806/3000], Loss: 11.5701\n",
      "Epoch [807/3000], Loss: 11.5585\n",
      "Epoch [808/3000], Loss: 11.5468\n",
      "Epoch [809/3000], Loss: 11.5352\n",
      "Epoch [810/3000], Loss: 11.5236\n",
      "Epoch [811/3000], Loss: 11.5120\n",
      "Epoch [812/3000], Loss: 11.5005\n",
      "Epoch [813/3000], Loss: 11.4889\n",
      "Epoch [814/3000], Loss: 11.4774\n",
      "Epoch [815/3000], Loss: 11.4659\n",
      "Epoch [816/3000], Loss: 11.4544\n",
      "Epoch [817/3000], Loss: 11.4429\n",
      "Epoch [818/3000], Loss: 11.4315\n",
      "Epoch [819/3000], Loss: 11.4201\n",
      "Epoch [820/3000], Loss: 11.4087\n",
      "Epoch [821/3000], Loss: 11.3974\n",
      "Epoch [822/3000], Loss: 11.3860\n",
      "Epoch [823/3000], Loss: 11.3746\n",
      "Epoch [824/3000], Loss: 11.3633\n",
      "Epoch [825/3000], Loss: 11.3521\n",
      "Epoch [826/3000], Loss: 11.3408\n",
      "Epoch [827/3000], Loss: 11.3296\n",
      "Epoch [828/3000], Loss: 11.3183\n",
      "Epoch [829/3000], Loss: 11.3071\n",
      "Epoch [830/3000], Loss: 11.2959\n",
      "Epoch [831/3000], Loss: 11.2847\n",
      "Epoch [832/3000], Loss: 11.2736\n",
      "Epoch [833/3000], Loss: 11.2624\n",
      "Epoch [834/3000], Loss: 11.2513\n",
      "Epoch [835/3000], Loss: 11.2402\n",
      "Epoch [836/3000], Loss: 11.2292\n",
      "Epoch [837/3000], Loss: 11.2181\n",
      "Epoch [838/3000], Loss: 11.2071\n",
      "Epoch [839/3000], Loss: 11.1961\n",
      "Epoch [840/3000], Loss: 11.1852\n",
      "Epoch [841/3000], Loss: 11.1742\n",
      "Epoch [842/3000], Loss: 11.1632\n",
      "Epoch [843/3000], Loss: 11.1523\n",
      "Epoch [844/3000], Loss: 11.1414\n",
      "Epoch [845/3000], Loss: 11.1305\n",
      "Epoch [846/3000], Loss: 11.1196\n",
      "Epoch [847/3000], Loss: 11.1088\n",
      "Epoch [848/3000], Loss: 11.0979\n",
      "Epoch [849/3000], Loss: 11.0871\n",
      "Epoch [850/3000], Loss: 11.0762\n",
      "Epoch [851/3000], Loss: 11.0653\n",
      "Epoch [852/3000], Loss: 11.0545\n",
      "Epoch [853/3000], Loss: 11.0436\n",
      "Epoch [854/3000], Loss: 11.0328\n",
      "Epoch [855/3000], Loss: 11.0220\n",
      "Epoch [856/3000], Loss: 11.0112\n",
      "Epoch [857/3000], Loss: 11.0004\n",
      "Epoch [858/3000], Loss: 10.9896\n",
      "Epoch [859/3000], Loss: 10.9788\n",
      "Epoch [860/3000], Loss: 10.9680\n",
      "Epoch [861/3000], Loss: 10.9572\n",
      "Epoch [862/3000], Loss: 10.9465\n",
      "Epoch [863/3000], Loss: 10.9358\n",
      "Epoch [864/3000], Loss: 10.9251\n",
      "Epoch [865/3000], Loss: 10.9144\n",
      "Epoch [866/3000], Loss: 10.9036\n",
      "Epoch [867/3000], Loss: 10.8928\n",
      "Epoch [868/3000], Loss: 10.8821\n",
      "Epoch [869/3000], Loss: 10.8714\n",
      "Epoch [870/3000], Loss: 10.8608\n",
      "Epoch [871/3000], Loss: 10.8502\n",
      "Epoch [872/3000], Loss: 10.8397\n",
      "Epoch [873/3000], Loss: 10.8290\n",
      "Epoch [874/3000], Loss: 10.8183\n",
      "Epoch [875/3000], Loss: 10.8076\n",
      "Epoch [876/3000], Loss: 10.7969\n",
      "Epoch [877/3000], Loss: 10.7862\n",
      "Epoch [878/3000], Loss: 10.7756\n",
      "Epoch [879/3000], Loss: 10.7651\n",
      "Epoch [880/3000], Loss: 10.7545\n",
      "Epoch [881/3000], Loss: 10.7439\n",
      "Epoch [882/3000], Loss: 10.7332\n",
      "Epoch [883/3000], Loss: 10.7226\n",
      "Epoch [884/3000], Loss: 10.7119\n",
      "Epoch [885/3000], Loss: 10.7013\n",
      "Epoch [886/3000], Loss: 10.6908\n",
      "Epoch [887/3000], Loss: 10.6802\n",
      "Epoch [888/3000], Loss: 10.6697\n",
      "Epoch [889/3000], Loss: 10.6592\n",
      "Epoch [890/3000], Loss: 10.6486\n",
      "Epoch [891/3000], Loss: 10.6380\n",
      "Epoch [892/3000], Loss: 10.6274\n",
      "Epoch [893/3000], Loss: 10.6167\n",
      "Epoch [894/3000], Loss: 10.6061\n",
      "Epoch [895/3000], Loss: 10.5955\n",
      "Epoch [896/3000], Loss: 10.5849\n",
      "Epoch [897/3000], Loss: 10.5742\n",
      "Epoch [898/3000], Loss: 10.5635\n",
      "Epoch [899/3000], Loss: 10.5528\n",
      "Epoch [900/3000], Loss: 10.5421\n",
      "Epoch [901/3000], Loss: 10.5314\n",
      "Epoch [902/3000], Loss: 10.5207\n",
      "Epoch [903/3000], Loss: 10.5100\n",
      "Epoch [904/3000], Loss: 10.4993\n",
      "Epoch [905/3000], Loss: 10.4886\n",
      "Epoch [906/3000], Loss: 10.4779\n",
      "Epoch [907/3000], Loss: 10.4672\n",
      "Epoch [908/3000], Loss: 10.4566\n",
      "Epoch [909/3000], Loss: 10.4459\n",
      "Epoch [910/3000], Loss: 10.4352\n",
      "Epoch [911/3000], Loss: 10.4246\n",
      "Epoch [912/3000], Loss: 10.4140\n",
      "Epoch [913/3000], Loss: 10.4035\n",
      "Epoch [914/3000], Loss: 10.3929\n",
      "Epoch [915/3000], Loss: 10.3823\n",
      "Epoch [916/3000], Loss: 10.3718\n",
      "Epoch [917/3000], Loss: 10.3613\n",
      "Epoch [918/3000], Loss: 10.3508\n",
      "Epoch [919/3000], Loss: 10.3404\n",
      "Epoch [920/3000], Loss: 10.3299\n",
      "Epoch [921/3000], Loss: 10.3194\n",
      "Epoch [922/3000], Loss: 10.3089\n",
      "Epoch [923/3000], Loss: 10.2985\n",
      "Epoch [924/3000], Loss: 10.2880\n",
      "Epoch [925/3000], Loss: 10.2775\n",
      "Epoch [926/3000], Loss: 10.2671\n",
      "Epoch [927/3000], Loss: 10.2566\n",
      "Epoch [928/3000], Loss: 10.2461\n",
      "Epoch [929/3000], Loss: 10.2356\n",
      "Epoch [930/3000], Loss: 10.2252\n",
      "Epoch [931/3000], Loss: 10.2148\n",
      "Epoch [932/3000], Loss: 10.2043\n",
      "Epoch [933/3000], Loss: 10.1939\n",
      "Epoch [934/3000], Loss: 10.1835\n",
      "Epoch [935/3000], Loss: 10.1732\n",
      "Epoch [936/3000], Loss: 10.1628\n",
      "Epoch [937/3000], Loss: 10.1524\n",
      "Epoch [938/3000], Loss: 10.1421\n",
      "Epoch [939/3000], Loss: 10.1318\n",
      "Epoch [940/3000], Loss: 10.1215\n",
      "Epoch [941/3000], Loss: 10.1113\n",
      "Epoch [942/3000], Loss: 10.1010\n",
      "Epoch [943/3000], Loss: 10.0908\n",
      "Epoch [944/3000], Loss: 10.0806\n",
      "Epoch [945/3000], Loss: 10.0703\n",
      "Epoch [946/3000], Loss: 10.0600\n",
      "Epoch [947/3000], Loss: 10.0497\n",
      "Epoch [948/3000], Loss: 10.0394\n",
      "Epoch [949/3000], Loss: 10.0290\n",
      "Epoch [950/3000], Loss: 10.0186\n",
      "Epoch [951/3000], Loss: 10.0081\n",
      "Epoch [952/3000], Loss: 9.9976\n",
      "Epoch [953/3000], Loss: 9.9870\n",
      "Epoch [954/3000], Loss: 9.9764\n",
      "Epoch [955/3000], Loss: 9.9657\n",
      "Epoch [956/3000], Loss: 9.9551\n",
      "Epoch [957/3000], Loss: 9.9443\n",
      "Epoch [958/3000], Loss: 9.9336\n",
      "Epoch [959/3000], Loss: 9.9227\n",
      "Epoch [960/3000], Loss: 9.9116\n",
      "Epoch [961/3000], Loss: 9.9005\n",
      "Epoch [962/3000], Loss: 9.8892\n",
      "Epoch [963/3000], Loss: 9.8778\n",
      "Epoch [964/3000], Loss: 9.8665\n",
      "Epoch [965/3000], Loss: 9.8550\n",
      "Epoch [966/3000], Loss: 9.8434\n",
      "Epoch [967/3000], Loss: 9.8316\n",
      "Epoch [968/3000], Loss: 9.8198\n",
      "Epoch [969/3000], Loss: 9.8081\n",
      "Epoch [970/3000], Loss: 9.7964\n",
      "Epoch [971/3000], Loss: 9.7845\n",
      "Epoch [972/3000], Loss: 9.7726\n",
      "Epoch [973/3000], Loss: 9.7606\n",
      "Epoch [974/3000], Loss: 9.7486\n",
      "Epoch [975/3000], Loss: 9.7365\n",
      "Epoch [976/3000], Loss: 9.7245\n",
      "Epoch [977/3000], Loss: 9.7125\n",
      "Epoch [978/3000], Loss: 9.7003\n",
      "Epoch [979/3000], Loss: 9.6882\n",
      "Epoch [980/3000], Loss: 9.6760\n",
      "Epoch [981/3000], Loss: 9.6637\n",
      "Epoch [982/3000], Loss: 9.6513\n",
      "Epoch [983/3000], Loss: 9.6387\n",
      "Epoch [984/3000], Loss: 9.6261\n",
      "Epoch [985/3000], Loss: 9.6134\n",
      "Epoch [986/3000], Loss: 9.6007\n",
      "Epoch [987/3000], Loss: 9.5881\n",
      "Epoch [988/3000], Loss: 9.5755\n",
      "Epoch [989/3000], Loss: 9.5630\n",
      "Epoch [990/3000], Loss: 9.5504\n",
      "Epoch [991/3000], Loss: 9.5379\n",
      "Epoch [992/3000], Loss: 9.5252\n",
      "Epoch [993/3000], Loss: 9.5125\n",
      "Epoch [994/3000], Loss: 9.4999\n",
      "Epoch [995/3000], Loss: 9.4873\n",
      "Epoch [996/3000], Loss: 9.4748\n",
      "Epoch [997/3000], Loss: 9.4624\n",
      "Epoch [998/3000], Loss: 9.4500\n",
      "Epoch [999/3000], Loss: 9.4377\n",
      "Epoch [1000/3000], Loss: 9.4254\n",
      "Epoch [1001/3000], Loss: 9.4132\n",
      "Epoch [1002/3000], Loss: 9.4011\n",
      "Epoch [1003/3000], Loss: 9.3890\n",
      "Epoch [1004/3000], Loss: 9.3769\n",
      "Epoch [1005/3000], Loss: 9.3648\n",
      "Epoch [1006/3000], Loss: 9.3527\n",
      "Epoch [1007/3000], Loss: 9.3407\n",
      "Epoch [1008/3000], Loss: 9.3287\n",
      "Epoch [1009/3000], Loss: 9.3168\n",
      "Epoch [1010/3000], Loss: 9.3048\n",
      "Epoch [1011/3000], Loss: 9.2929\n",
      "Epoch [1012/3000], Loss: 9.2810\n",
      "Epoch [1013/3000], Loss: 9.2691\n",
      "Epoch [1014/3000], Loss: 9.2572\n",
      "Epoch [1015/3000], Loss: 9.2454\n",
      "Epoch [1016/3000], Loss: 9.2335\n",
      "Epoch [1017/3000], Loss: 9.2217\n",
      "Epoch [1018/3000], Loss: 9.2099\n",
      "Epoch [1019/3000], Loss: 9.1981\n",
      "Epoch [1020/3000], Loss: 9.1864\n",
      "Epoch [1021/3000], Loss: 9.1746\n",
      "Epoch [1022/3000], Loss: 9.1628\n",
      "Epoch [1023/3000], Loss: 9.1512\n",
      "Epoch [1024/3000], Loss: 9.1396\n",
      "Epoch [1025/3000], Loss: 9.1281\n",
      "Epoch [1026/3000], Loss: 9.1167\n",
      "Epoch [1027/3000], Loss: 9.1054\n",
      "Epoch [1028/3000], Loss: 9.0942\n",
      "Epoch [1029/3000], Loss: 9.0831\n",
      "Epoch [1030/3000], Loss: 9.0721\n",
      "Epoch [1031/3000], Loss: 9.0611\n",
      "Epoch [1032/3000], Loss: 9.0502\n",
      "Epoch [1033/3000], Loss: 9.0394\n",
      "Epoch [1034/3000], Loss: 9.0286\n",
      "Epoch [1035/3000], Loss: 9.0180\n",
      "Epoch [1036/3000], Loss: 9.0074\n",
      "Epoch [1037/3000], Loss: 8.9969\n",
      "Epoch [1038/3000], Loss: 8.9865\n",
      "Epoch [1039/3000], Loss: 8.9761\n",
      "Epoch [1040/3000], Loss: 8.9658\n",
      "Epoch [1041/3000], Loss: 8.9556\n",
      "Epoch [1042/3000], Loss: 8.9455\n",
      "Epoch [1043/3000], Loss: 8.9356\n",
      "Epoch [1044/3000], Loss: 8.9258\n",
      "Epoch [1045/3000], Loss: 8.9161\n",
      "Epoch [1046/3000], Loss: 8.9065\n",
      "Epoch [1047/3000], Loss: 8.8968\n",
      "Epoch [1048/3000], Loss: 8.8869\n",
      "Epoch [1049/3000], Loss: 8.8771\n",
      "Epoch [1050/3000], Loss: 8.8675\n",
      "Epoch [1051/3000], Loss: 8.8581\n",
      "Epoch [1052/3000], Loss: 8.8487\n",
      "Epoch [1053/3000], Loss: 8.8395\n",
      "Epoch [1054/3000], Loss: 8.8303\n",
      "Epoch [1055/3000], Loss: 8.8211\n",
      "Epoch [1056/3000], Loss: 8.8118\n",
      "Epoch [1057/3000], Loss: 8.8026\n",
      "Epoch [1058/3000], Loss: 8.7935\n",
      "Epoch [1059/3000], Loss: 8.7844\n",
      "Epoch [1060/3000], Loss: 8.7754\n",
      "Epoch [1061/3000], Loss: 8.7665\n",
      "Epoch [1062/3000], Loss: 8.7577\n",
      "Epoch [1063/3000], Loss: 8.7488\n",
      "Epoch [1064/3000], Loss: 8.7399\n",
      "Epoch [1065/3000], Loss: 8.7311\n",
      "Epoch [1066/3000], Loss: 8.7224\n",
      "Epoch [1067/3000], Loss: 8.7138\n",
      "Epoch [1068/3000], Loss: 8.7051\n",
      "Epoch [1069/3000], Loss: 8.6965\n",
      "Epoch [1070/3000], Loss: 8.6879\n",
      "Epoch [1071/3000], Loss: 8.6793\n",
      "Epoch [1072/3000], Loss: 8.6708\n",
      "Epoch [1073/3000], Loss: 8.6624\n",
      "Epoch [1074/3000], Loss: 8.6540\n",
      "Epoch [1075/3000], Loss: 8.6456\n",
      "Epoch [1076/3000], Loss: 8.6373\n",
      "Epoch [1077/3000], Loss: 8.6290\n",
      "Epoch [1078/3000], Loss: 8.6208\n",
      "Epoch [1079/3000], Loss: 8.6126\n",
      "Epoch [1080/3000], Loss: 8.6044\n",
      "Epoch [1081/3000], Loss: 8.5963\n",
      "Epoch [1082/3000], Loss: 8.5882\n",
      "Epoch [1083/3000], Loss: 8.5801\n",
      "Epoch [1084/3000], Loss: 8.5721\n",
      "Epoch [1085/3000], Loss: 8.5640\n",
      "Epoch [1086/3000], Loss: 8.5560\n",
      "Epoch [1087/3000], Loss: 8.5481\n",
      "Epoch [1088/3000], Loss: 8.5402\n",
      "Epoch [1089/3000], Loss: 8.5324\n",
      "Epoch [1090/3000], Loss: 8.5246\n",
      "Epoch [1091/3000], Loss: 8.5167\n",
      "Epoch [1092/3000], Loss: 8.5090\n",
      "Epoch [1093/3000], Loss: 8.5012\n",
      "Epoch [1094/3000], Loss: 8.4935\n",
      "Epoch [1095/3000], Loss: 8.4858\n",
      "Epoch [1096/3000], Loss: 8.4782\n",
      "Epoch [1097/3000], Loss: 8.4706\n",
      "Epoch [1098/3000], Loss: 8.4630\n",
      "Epoch [1099/3000], Loss: 8.4555\n",
      "Epoch [1100/3000], Loss: 8.4480\n",
      "Epoch [1101/3000], Loss: 8.4405\n",
      "Epoch [1102/3000], Loss: 8.4330\n",
      "Epoch [1103/3000], Loss: 8.4255\n",
      "Epoch [1104/3000], Loss: 8.4181\n",
      "Epoch [1105/3000], Loss: 8.4108\n",
      "Epoch [1106/3000], Loss: 8.4034\n",
      "Epoch [1107/3000], Loss: 8.3961\n",
      "Epoch [1108/3000], Loss: 8.3887\n",
      "Epoch [1109/3000], Loss: 8.3814\n",
      "Epoch [1110/3000], Loss: 8.3742\n",
      "Epoch [1111/3000], Loss: 8.3669\n",
      "Epoch [1112/3000], Loss: 8.3597\n",
      "Epoch [1113/3000], Loss: 8.3525\n",
      "Epoch [1114/3000], Loss: 8.3453\n",
      "Epoch [1115/3000], Loss: 8.3381\n",
      "Epoch [1116/3000], Loss: 8.3309\n",
      "Epoch [1117/3000], Loss: 8.3238\n",
      "Epoch [1118/3000], Loss: 8.3167\n",
      "Epoch [1119/3000], Loss: 8.3096\n",
      "Epoch [1120/3000], Loss: 8.3025\n",
      "Epoch [1121/3000], Loss: 8.2955\n",
      "Epoch [1122/3000], Loss: 8.2885\n",
      "Epoch [1123/3000], Loss: 8.2815\n",
      "Epoch [1124/3000], Loss: 8.2746\n",
      "Epoch [1125/3000], Loss: 8.2677\n",
      "Epoch [1126/3000], Loss: 8.2608\n",
      "Epoch [1127/3000], Loss: 8.2540\n",
      "Epoch [1128/3000], Loss: 8.2472\n",
      "Epoch [1129/3000], Loss: 8.2405\n",
      "Epoch [1130/3000], Loss: 8.2337\n",
      "Epoch [1131/3000], Loss: 8.2269\n",
      "Epoch [1132/3000], Loss: 8.2200\n",
      "Epoch [1133/3000], Loss: 8.2131\n",
      "Epoch [1134/3000], Loss: 8.2063\n",
      "Epoch [1135/3000], Loss: 8.1995\n",
      "Epoch [1136/3000], Loss: 8.1928\n",
      "Epoch [1137/3000], Loss: 8.1861\n",
      "Epoch [1138/3000], Loss: 8.1794\n",
      "Epoch [1139/3000], Loss: 8.1728\n",
      "Epoch [1140/3000], Loss: 8.1662\n",
      "Epoch [1141/3000], Loss: 8.1596\n",
      "Epoch [1142/3000], Loss: 8.1531\n",
      "Epoch [1143/3000], Loss: 8.1465\n",
      "Epoch [1144/3000], Loss: 8.1399\n",
      "Epoch [1145/3000], Loss: 8.1333\n",
      "Epoch [1146/3000], Loss: 8.1267\n",
      "Epoch [1147/3000], Loss: 8.1201\n",
      "Epoch [1148/3000], Loss: 8.1136\n",
      "Epoch [1149/3000], Loss: 8.1071\n",
      "Epoch [1150/3000], Loss: 8.1007\n",
      "Epoch [1151/3000], Loss: 8.0942\n",
      "Epoch [1152/3000], Loss: 8.0878\n",
      "Epoch [1153/3000], Loss: 8.0814\n",
      "Epoch [1154/3000], Loss: 8.0751\n",
      "Epoch [1155/3000], Loss: 8.0687\n",
      "Epoch [1156/3000], Loss: 8.0624\n",
      "Epoch [1157/3000], Loss: 8.0560\n",
      "Epoch [1158/3000], Loss: 8.0496\n",
      "Epoch [1159/3000], Loss: 8.0433\n",
      "Epoch [1160/3000], Loss: 8.0370\n",
      "Epoch [1161/3000], Loss: 8.0307\n",
      "Epoch [1162/3000], Loss: 8.0245\n",
      "Epoch [1163/3000], Loss: 8.0183\n",
      "Epoch [1164/3000], Loss: 8.0120\n",
      "Epoch [1165/3000], Loss: 8.0058\n",
      "Epoch [1166/3000], Loss: 7.9995\n",
      "Epoch [1167/3000], Loss: 7.9933\n",
      "Epoch [1168/3000], Loss: 7.9871\n",
      "Epoch [1169/3000], Loss: 7.9809\n",
      "Epoch [1170/3000], Loss: 7.9747\n",
      "Epoch [1171/3000], Loss: 7.9686\n",
      "Epoch [1172/3000], Loss: 7.9625\n",
      "Epoch [1173/3000], Loss: 7.9564\n",
      "Epoch [1174/3000], Loss: 7.9503\n",
      "Epoch [1175/3000], Loss: 7.9442\n",
      "Epoch [1176/3000], Loss: 7.9381\n",
      "Epoch [1177/3000], Loss: 7.9321\n",
      "Epoch [1178/3000], Loss: 7.9260\n",
      "Epoch [1179/3000], Loss: 7.9200\n",
      "Epoch [1180/3000], Loss: 7.9140\n",
      "Epoch [1181/3000], Loss: 7.9080\n",
      "Epoch [1182/3000], Loss: 7.9020\n",
      "Epoch [1183/3000], Loss: 7.8961\n",
      "Epoch [1184/3000], Loss: 7.8901\n",
      "Epoch [1185/3000], Loss: 7.8842\n",
      "Epoch [1186/3000], Loss: 7.8784\n",
      "Epoch [1187/3000], Loss: 7.8726\n",
      "Epoch [1188/3000], Loss: 7.8668\n",
      "Epoch [1189/3000], Loss: 7.8610\n",
      "Epoch [1190/3000], Loss: 7.8552\n",
      "Epoch [1191/3000], Loss: 7.8494\n",
      "Epoch [1192/3000], Loss: 7.8438\n",
      "Epoch [1193/3000], Loss: 7.8383\n",
      "Epoch [1194/3000], Loss: 7.8327\n",
      "Epoch [1195/3000], Loss: 7.8268\n",
      "Epoch [1196/3000], Loss: 7.8205\n",
      "Epoch [1197/3000], Loss: 7.8144\n",
      "Epoch [1198/3000], Loss: 7.8086\n",
      "Epoch [1199/3000], Loss: 7.8031\n",
      "Epoch [1200/3000], Loss: 7.7976\n",
      "Epoch [1201/3000], Loss: 7.7920\n",
      "Epoch [1202/3000], Loss: 7.7861\n",
      "Epoch [1203/3000], Loss: 7.7803\n",
      "Epoch [1204/3000], Loss: 7.7747\n",
      "Epoch [1205/3000], Loss: 7.7692\n",
      "Epoch [1206/3000], Loss: 7.7637\n",
      "Epoch [1207/3000], Loss: 7.7581\n",
      "Epoch [1208/3000], Loss: 7.7523\n",
      "Epoch [1209/3000], Loss: 7.7467\n",
      "Epoch [1210/3000], Loss: 7.7412\n",
      "Epoch [1211/3000], Loss: 7.7357\n",
      "Epoch [1212/3000], Loss: 7.7301\n",
      "Epoch [1213/3000], Loss: 7.7246\n",
      "Epoch [1214/3000], Loss: 7.7191\n",
      "Epoch [1215/3000], Loss: 7.7136\n",
      "Epoch [1216/3000], Loss: 7.7081\n",
      "Epoch [1217/3000], Loss: 7.7026\n",
      "Epoch [1218/3000], Loss: 7.6971\n",
      "Epoch [1219/3000], Loss: 7.6917\n",
      "Epoch [1220/3000], Loss: 7.6862\n",
      "Epoch [1221/3000], Loss: 7.6808\n",
      "Epoch [1222/3000], Loss: 7.6754\n",
      "Epoch [1223/3000], Loss: 7.6700\n",
      "Epoch [1224/3000], Loss: 7.6646\n",
      "Epoch [1225/3000], Loss: 7.6592\n",
      "Epoch [1226/3000], Loss: 7.6539\n",
      "Epoch [1227/3000], Loss: 7.6485\n",
      "Epoch [1228/3000], Loss: 7.6432\n",
      "Epoch [1229/3000], Loss: 7.6379\n",
      "Epoch [1230/3000], Loss: 7.6326\n",
      "Epoch [1231/3000], Loss: 7.6273\n",
      "Epoch [1232/3000], Loss: 7.6220\n",
      "Epoch [1233/3000], Loss: 7.6167\n",
      "Epoch [1234/3000], Loss: 7.6114\n",
      "Epoch [1235/3000], Loss: 7.6061\n",
      "Epoch [1236/3000], Loss: 7.6008\n",
      "Epoch [1237/3000], Loss: 7.5956\n",
      "Epoch [1238/3000], Loss: 7.5903\n",
      "Epoch [1239/3000], Loss: 7.5851\n",
      "Epoch [1240/3000], Loss: 7.5798\n",
      "Epoch [1241/3000], Loss: 7.5746\n",
      "Epoch [1242/3000], Loss: 7.5694\n",
      "Epoch [1243/3000], Loss: 7.5642\n",
      "Epoch [1244/3000], Loss: 7.5590\n",
      "Epoch [1245/3000], Loss: 7.5539\n",
      "Epoch [1246/3000], Loss: 7.5487\n",
      "Epoch [1247/3000], Loss: 7.5435\n",
      "Epoch [1248/3000], Loss: 7.5384\n",
      "Epoch [1249/3000], Loss: 7.5332\n",
      "Epoch [1250/3000], Loss: 7.5280\n",
      "Epoch [1251/3000], Loss: 7.5229\n",
      "Epoch [1252/3000], Loss: 7.5177\n",
      "Epoch [1253/3000], Loss: 7.5126\n",
      "Epoch [1254/3000], Loss: 7.5074\n",
      "Epoch [1255/3000], Loss: 7.5023\n",
      "Epoch [1256/3000], Loss: 7.4971\n",
      "Epoch [1257/3000], Loss: 7.4920\n",
      "Epoch [1258/3000], Loss: 7.4868\n",
      "Epoch [1259/3000], Loss: 7.4817\n",
      "Epoch [1260/3000], Loss: 7.4766\n",
      "Epoch [1261/3000], Loss: 7.4715\n",
      "Epoch [1262/3000], Loss: 7.4664\n",
      "Epoch [1263/3000], Loss: 7.4614\n",
      "Epoch [1264/3000], Loss: 7.4564\n",
      "Epoch [1265/3000], Loss: 7.4514\n",
      "Epoch [1266/3000], Loss: 7.4464\n",
      "Epoch [1267/3000], Loss: 7.4415\n",
      "Epoch [1268/3000], Loss: 7.4366\n",
      "Epoch [1269/3000], Loss: 7.4317\n",
      "Epoch [1270/3000], Loss: 7.4268\n",
      "Epoch [1271/3000], Loss: 7.4218\n",
      "Epoch [1272/3000], Loss: 7.4167\n",
      "Epoch [1273/3000], Loss: 7.4115\n",
      "Epoch [1274/3000], Loss: 7.4064\n",
      "Epoch [1275/3000], Loss: 7.4013\n",
      "Epoch [1276/3000], Loss: 7.3963\n",
      "Epoch [1277/3000], Loss: 7.3913\n",
      "Epoch [1278/3000], Loss: 7.3864\n",
      "Epoch [1279/3000], Loss: 7.3816\n",
      "Epoch [1280/3000], Loss: 7.3767\n",
      "Epoch [1281/3000], Loss: 7.3719\n",
      "Epoch [1282/3000], Loss: 7.3670\n",
      "Epoch [1283/3000], Loss: 7.3621\n",
      "Epoch [1284/3000], Loss: 7.3571\n",
      "Epoch [1285/3000], Loss: 7.3522\n",
      "Epoch [1286/3000], Loss: 7.3473\n",
      "Epoch [1287/3000], Loss: 7.3423\n",
      "Epoch [1288/3000], Loss: 7.3374\n",
      "Epoch [1289/3000], Loss: 7.3325\n",
      "Epoch [1290/3000], Loss: 7.3277\n",
      "Epoch [1291/3000], Loss: 7.3228\n",
      "Epoch [1292/3000], Loss: 7.3180\n",
      "Epoch [1293/3000], Loss: 7.3131\n",
      "Epoch [1294/3000], Loss: 7.3083\n",
      "Epoch [1295/3000], Loss: 7.3034\n",
      "Epoch [1296/3000], Loss: 7.2985\n",
      "Epoch [1297/3000], Loss: 7.2936\n",
      "Epoch [1298/3000], Loss: 7.2888\n",
      "Epoch [1299/3000], Loss: 7.2839\n",
      "Epoch [1300/3000], Loss: 7.2791\n",
      "Epoch [1301/3000], Loss: 7.2743\n",
      "Epoch [1302/3000], Loss: 7.2694\n",
      "Epoch [1303/3000], Loss: 7.2646\n",
      "Epoch [1304/3000], Loss: 7.2598\n",
      "Epoch [1305/3000], Loss: 7.2550\n",
      "Epoch [1306/3000], Loss: 7.2502\n",
      "Epoch [1307/3000], Loss: 7.2455\n",
      "Epoch [1308/3000], Loss: 7.2407\n",
      "Epoch [1309/3000], Loss: 7.2359\n",
      "Epoch [1310/3000], Loss: 7.2312\n",
      "Epoch [1311/3000], Loss: 7.2264\n",
      "Epoch [1312/3000], Loss: 7.2217\n",
      "Epoch [1313/3000], Loss: 7.2169\n",
      "Epoch [1314/3000], Loss: 7.2122\n",
      "Epoch [1315/3000], Loss: 7.2075\n",
      "Epoch [1316/3000], Loss: 7.2028\n",
      "Epoch [1317/3000], Loss: 7.1981\n",
      "Epoch [1318/3000], Loss: 7.1934\n",
      "Epoch [1319/3000], Loss: 7.1887\n",
      "Epoch [1320/3000], Loss: 7.1840\n",
      "Epoch [1321/3000], Loss: 7.1794\n",
      "Epoch [1322/3000], Loss: 7.1747\n",
      "Epoch [1323/3000], Loss: 7.1701\n",
      "Epoch [1324/3000], Loss: 7.1655\n",
      "Epoch [1325/3000], Loss: 7.1609\n",
      "Epoch [1326/3000], Loss: 7.1563\n",
      "Epoch [1327/3000], Loss: 7.1518\n",
      "Epoch [1328/3000], Loss: 7.1473\n",
      "Epoch [1329/3000], Loss: 7.1427\n",
      "Epoch [1330/3000], Loss: 7.1380\n",
      "Epoch [1331/3000], Loss: 7.1333\n",
      "Epoch [1332/3000], Loss: 7.1287\n",
      "Epoch [1333/3000], Loss: 7.1240\n",
      "Epoch [1334/3000], Loss: 7.1194\n",
      "Epoch [1335/3000], Loss: 7.1148\n",
      "Epoch [1336/3000], Loss: 7.1102\n",
      "Epoch [1337/3000], Loss: 7.1057\n",
      "Epoch [1338/3000], Loss: 7.1012\n",
      "Epoch [1339/3000], Loss: 7.0966\n",
      "Epoch [1340/3000], Loss: 7.0921\n",
      "Epoch [1341/3000], Loss: 7.0876\n",
      "Epoch [1342/3000], Loss: 7.0832\n",
      "Epoch [1343/3000], Loss: 7.0787\n",
      "Epoch [1344/3000], Loss: 7.0743\n",
      "Epoch [1345/3000], Loss: 7.0699\n",
      "Epoch [1346/3000], Loss: 7.0654\n",
      "Epoch [1347/3000], Loss: 7.0610\n",
      "Epoch [1348/3000], Loss: 7.0566\n",
      "Epoch [1349/3000], Loss: 7.0521\n",
      "Epoch [1350/3000], Loss: 7.0477\n",
      "Epoch [1351/3000], Loss: 7.0432\n",
      "Epoch [1352/3000], Loss: 7.0388\n",
      "Epoch [1353/3000], Loss: 7.0343\n",
      "Epoch [1354/3000], Loss: 7.0298\n",
      "Epoch [1355/3000], Loss: 7.0254\n",
      "Epoch [1356/3000], Loss: 7.0210\n",
      "Epoch [1357/3000], Loss: 7.0165\n",
      "Epoch [1358/3000], Loss: 7.0121\n",
      "Epoch [1359/3000], Loss: 7.0078\n",
      "Epoch [1360/3000], Loss: 7.0034\n",
      "Epoch [1361/3000], Loss: 6.9991\n",
      "Epoch [1362/3000], Loss: 6.9948\n",
      "Epoch [1363/3000], Loss: 6.9905\n",
      "Epoch [1364/3000], Loss: 6.9861\n",
      "Epoch [1365/3000], Loss: 6.9818\n",
      "Epoch [1366/3000], Loss: 6.9775\n",
      "Epoch [1367/3000], Loss: 6.9732\n",
      "Epoch [1368/3000], Loss: 6.9689\n",
      "Epoch [1369/3000], Loss: 6.9647\n",
      "Epoch [1370/3000], Loss: 6.9604\n",
      "Epoch [1371/3000], Loss: 6.9561\n",
      "Epoch [1372/3000], Loss: 6.9518\n",
      "Epoch [1373/3000], Loss: 6.9476\n",
      "Epoch [1374/3000], Loss: 6.9433\n",
      "Epoch [1375/3000], Loss: 6.9391\n",
      "Epoch [1376/3000], Loss: 6.9348\n",
      "Epoch [1377/3000], Loss: 6.9306\n",
      "Epoch [1378/3000], Loss: 6.9263\n",
      "Epoch [1379/3000], Loss: 6.9221\n",
      "Epoch [1380/3000], Loss: 6.9178\n",
      "Epoch [1381/3000], Loss: 6.9136\n",
      "Epoch [1382/3000], Loss: 6.9094\n",
      "Epoch [1383/3000], Loss: 6.9053\n",
      "Epoch [1384/3000], Loss: 6.9011\n",
      "Epoch [1385/3000], Loss: 6.8969\n",
      "Epoch [1386/3000], Loss: 6.8927\n",
      "Epoch [1387/3000], Loss: 6.8884\n",
      "Epoch [1388/3000], Loss: 6.8842\n",
      "Epoch [1389/3000], Loss: 6.8801\n",
      "Epoch [1390/3000], Loss: 6.8758\n",
      "Epoch [1391/3000], Loss: 6.8716\n",
      "Epoch [1392/3000], Loss: 6.8673\n",
      "Epoch [1393/3000], Loss: 6.8631\n",
      "Epoch [1394/3000], Loss: 6.8589\n",
      "Epoch [1395/3000], Loss: 6.8547\n",
      "Epoch [1396/3000], Loss: 6.8505\n",
      "Epoch [1397/3000], Loss: 6.8463\n",
      "Epoch [1398/3000], Loss: 6.8421\n",
      "Epoch [1399/3000], Loss: 6.8380\n",
      "Epoch [1400/3000], Loss: 6.8339\n",
      "Epoch [1401/3000], Loss: 6.8298\n",
      "Epoch [1402/3000], Loss: 6.8257\n",
      "Epoch [1403/3000], Loss: 6.8216\n",
      "Epoch [1404/3000], Loss: 6.8175\n",
      "Epoch [1405/3000], Loss: 6.8133\n",
      "Epoch [1406/3000], Loss: 6.8091\n",
      "Epoch [1407/3000], Loss: 6.8049\n",
      "Epoch [1408/3000], Loss: 6.8007\n",
      "Epoch [1409/3000], Loss: 6.7965\n",
      "Epoch [1410/3000], Loss: 6.7924\n",
      "Epoch [1411/3000], Loss: 6.7883\n",
      "Epoch [1412/3000], Loss: 6.7842\n",
      "Epoch [1413/3000], Loss: 6.7801\n",
      "Epoch [1414/3000], Loss: 6.7761\n",
      "Epoch [1415/3000], Loss: 6.7721\n",
      "Epoch [1416/3000], Loss: 6.7680\n",
      "Epoch [1417/3000], Loss: 6.7640\n",
      "Epoch [1418/3000], Loss: 6.7600\n",
      "Epoch [1419/3000], Loss: 6.7559\n",
      "Epoch [1420/3000], Loss: 6.7518\n",
      "Epoch [1421/3000], Loss: 6.7475\n",
      "Epoch [1422/3000], Loss: 6.7434\n",
      "Epoch [1423/3000], Loss: 6.7392\n",
      "Epoch [1424/3000], Loss: 6.7352\n",
      "Epoch [1425/3000], Loss: 6.7312\n",
      "Epoch [1426/3000], Loss: 6.7272\n",
      "Epoch [1427/3000], Loss: 6.7233\n",
      "Epoch [1428/3000], Loss: 6.7193\n",
      "Epoch [1429/3000], Loss: 6.7154\n",
      "Epoch [1430/3000], Loss: 6.7114\n",
      "Epoch [1431/3000], Loss: 6.7073\n",
      "Epoch [1432/3000], Loss: 6.7033\n",
      "Epoch [1433/3000], Loss: 6.6992\n",
      "Epoch [1434/3000], Loss: 6.6952\n",
      "Epoch [1435/3000], Loss: 6.6912\n",
      "Epoch [1436/3000], Loss: 6.6872\n",
      "Epoch [1437/3000], Loss: 6.6832\n",
      "Epoch [1438/3000], Loss: 6.6793\n",
      "Epoch [1439/3000], Loss: 6.6754\n",
      "Epoch [1440/3000], Loss: 6.6715\n",
      "Epoch [1441/3000], Loss: 6.6676\n",
      "Epoch [1442/3000], Loss: 6.6637\n",
      "Epoch [1443/3000], Loss: 6.6598\n",
      "Epoch [1444/3000], Loss: 6.6558\n",
      "Epoch [1445/3000], Loss: 6.6519\n",
      "Epoch [1446/3000], Loss: 6.6480\n",
      "Epoch [1447/3000], Loss: 6.6441\n",
      "Epoch [1448/3000], Loss: 6.6402\n",
      "Epoch [1449/3000], Loss: 6.6363\n",
      "Epoch [1450/3000], Loss: 6.6325\n",
      "Epoch [1451/3000], Loss: 6.6286\n",
      "Epoch [1452/3000], Loss: 6.6248\n",
      "Epoch [1453/3000], Loss: 6.6209\n",
      "Epoch [1454/3000], Loss: 6.6171\n",
      "Epoch [1455/3000], Loss: 6.6132\n",
      "Epoch [1456/3000], Loss: 6.6094\n",
      "Epoch [1457/3000], Loss: 6.6056\n",
      "Epoch [1458/3000], Loss: 6.6017\n",
      "Epoch [1459/3000], Loss: 6.5979\n",
      "Epoch [1460/3000], Loss: 6.5941\n",
      "Epoch [1461/3000], Loss: 6.5903\n",
      "Epoch [1462/3000], Loss: 6.5864\n",
      "Epoch [1463/3000], Loss: 6.5826\n",
      "Epoch [1464/3000], Loss: 6.5788\n",
      "Epoch [1465/3000], Loss: 6.5750\n",
      "Epoch [1466/3000], Loss: 6.5712\n",
      "Epoch [1467/3000], Loss: 6.5674\n",
      "Epoch [1468/3000], Loss: 6.5636\n",
      "Epoch [1469/3000], Loss: 6.5598\n",
      "Epoch [1470/3000], Loss: 6.5561\n",
      "Epoch [1471/3000], Loss: 6.5523\n",
      "Epoch [1472/3000], Loss: 6.5487\n",
      "Epoch [1473/3000], Loss: 6.5450\n",
      "Epoch [1474/3000], Loss: 6.5413\n",
      "Epoch [1475/3000], Loss: 6.5376\n",
      "Epoch [1476/3000], Loss: 6.5339\n",
      "Epoch [1477/3000], Loss: 6.5301\n",
      "Epoch [1478/3000], Loss: 6.5263\n",
      "Epoch [1479/3000], Loss: 6.5223\n",
      "Epoch [1480/3000], Loss: 6.5183\n",
      "Epoch [1481/3000], Loss: 6.5143\n",
      "Epoch [1482/3000], Loss: 6.5104\n",
      "Epoch [1483/3000], Loss: 6.5066\n",
      "Epoch [1484/3000], Loss: 6.5029\n",
      "Epoch [1485/3000], Loss: 6.4992\n",
      "Epoch [1486/3000], Loss: 6.4955\n",
      "Epoch [1487/3000], Loss: 6.4918\n",
      "Epoch [1488/3000], Loss: 6.4881\n",
      "Epoch [1489/3000], Loss: 6.4843\n",
      "Epoch [1490/3000], Loss: 6.4806\n",
      "Epoch [1491/3000], Loss: 6.4768\n",
      "Epoch [1492/3000], Loss: 6.4730\n",
      "Epoch [1493/3000], Loss: 6.4692\n",
      "Epoch [1494/3000], Loss: 6.4655\n",
      "Epoch [1495/3000], Loss: 6.4617\n",
      "Epoch [1496/3000], Loss: 6.4580\n",
      "Epoch [1497/3000], Loss: 6.4543\n",
      "Epoch [1498/3000], Loss: 6.4506\n",
      "Epoch [1499/3000], Loss: 6.4469\n",
      "Epoch [1500/3000], Loss: 6.4432\n",
      "Epoch [1501/3000], Loss: 6.4395\n",
      "Epoch [1502/3000], Loss: 6.4358\n",
      "Epoch [1503/3000], Loss: 6.4321\n",
      "Epoch [1504/3000], Loss: 6.4284\n",
      "Epoch [1505/3000], Loss: 6.4246\n",
      "Epoch [1506/3000], Loss: 6.4209\n",
      "Epoch [1507/3000], Loss: 6.4172\n",
      "Epoch [1508/3000], Loss: 6.4134\n",
      "Epoch [1509/3000], Loss: 6.4097\n",
      "Epoch [1510/3000], Loss: 6.4059\n",
      "Epoch [1511/3000], Loss: 6.4022\n",
      "Epoch [1512/3000], Loss: 6.3984\n",
      "Epoch [1513/3000], Loss: 6.3947\n",
      "Epoch [1514/3000], Loss: 6.3910\n",
      "Epoch [1515/3000], Loss: 6.3873\n",
      "Epoch [1516/3000], Loss: 6.3836\n",
      "Epoch [1517/3000], Loss: 6.3799\n",
      "Epoch [1518/3000], Loss: 6.3762\n",
      "Epoch [1519/3000], Loss: 6.3726\n",
      "Epoch [1520/3000], Loss: 6.3689\n",
      "Epoch [1521/3000], Loss: 6.3652\n",
      "Epoch [1522/3000], Loss: 6.3615\n",
      "Epoch [1523/3000], Loss: 6.3578\n",
      "Epoch [1524/3000], Loss: 6.3541\n",
      "Epoch [1525/3000], Loss: 6.3505\n",
      "Epoch [1526/3000], Loss: 6.3468\n",
      "Epoch [1527/3000], Loss: 6.3431\n",
      "Epoch [1528/3000], Loss: 6.3394\n",
      "Epoch [1529/3000], Loss: 6.3357\n",
      "Epoch [1530/3000], Loss: 6.3321\n",
      "Epoch [1531/3000], Loss: 6.3284\n",
      "Epoch [1532/3000], Loss: 6.3247\n",
      "Epoch [1533/3000], Loss: 6.3211\n",
      "Epoch [1534/3000], Loss: 6.3174\n",
      "Epoch [1535/3000], Loss: 6.3137\n",
      "Epoch [1536/3000], Loss: 6.3101\n",
      "Epoch [1537/3000], Loss: 6.3065\n",
      "Epoch [1538/3000], Loss: 6.3029\n",
      "Epoch [1539/3000], Loss: 6.2994\n",
      "Epoch [1540/3000], Loss: 6.2958\n",
      "Epoch [1541/3000], Loss: 6.2922\n",
      "Epoch [1542/3000], Loss: 6.2886\n",
      "Epoch [1543/3000], Loss: 6.2850\n",
      "Epoch [1544/3000], Loss: 6.2813\n",
      "Epoch [1545/3000], Loss: 6.2776\n",
      "Epoch [1546/3000], Loss: 6.2737\n",
      "Epoch [1547/3000], Loss: 6.2698\n",
      "Epoch [1548/3000], Loss: 6.2658\n",
      "Epoch [1549/3000], Loss: 6.2620\n",
      "Epoch [1550/3000], Loss: 6.2583\n",
      "Epoch [1551/3000], Loss: 6.2546\n",
      "Epoch [1552/3000], Loss: 6.2510\n",
      "Epoch [1553/3000], Loss: 6.2474\n",
      "Epoch [1554/3000], Loss: 6.2439\n",
      "Epoch [1555/3000], Loss: 6.2402\n",
      "Epoch [1556/3000], Loss: 6.2365\n",
      "Epoch [1557/3000], Loss: 6.2328\n",
      "Epoch [1558/3000], Loss: 6.2290\n",
      "Epoch [1559/3000], Loss: 6.2252\n",
      "Epoch [1560/3000], Loss: 6.2215\n",
      "Epoch [1561/3000], Loss: 6.2177\n",
      "Epoch [1562/3000], Loss: 6.2140\n",
      "Epoch [1563/3000], Loss: 6.2104\n",
      "Epoch [1564/3000], Loss: 6.2068\n",
      "Epoch [1565/3000], Loss: 6.2031\n",
      "Epoch [1566/3000], Loss: 6.1995\n",
      "Epoch [1567/3000], Loss: 6.1958\n",
      "Epoch [1568/3000], Loss: 6.1921\n",
      "Epoch [1569/3000], Loss: 6.1884\n",
      "Epoch [1570/3000], Loss: 6.1847\n",
      "Epoch [1571/3000], Loss: 6.1810\n",
      "Epoch [1572/3000], Loss: 6.1774\n",
      "Epoch [1573/3000], Loss: 6.1737\n",
      "Epoch [1574/3000], Loss: 6.1701\n",
      "Epoch [1575/3000], Loss: 6.1664\n",
      "Epoch [1576/3000], Loss: 6.1628\n",
      "Epoch [1577/3000], Loss: 6.1592\n",
      "Epoch [1578/3000], Loss: 6.1556\n",
      "Epoch [1579/3000], Loss: 6.1520\n",
      "Epoch [1580/3000], Loss: 6.1484\n",
      "Epoch [1581/3000], Loss: 6.1448\n",
      "Epoch [1582/3000], Loss: 6.1412\n",
      "Epoch [1583/3000], Loss: 6.1376\n",
      "Epoch [1584/3000], Loss: 6.1340\n",
      "Epoch [1585/3000], Loss: 6.1305\n",
      "Epoch [1586/3000], Loss: 6.1269\n",
      "Epoch [1587/3000], Loss: 6.1233\n",
      "Epoch [1588/3000], Loss: 6.1198\n",
      "Epoch [1589/3000], Loss: 6.1162\n",
      "Epoch [1590/3000], Loss: 6.1126\n",
      "Epoch [1591/3000], Loss: 6.1091\n",
      "Epoch [1592/3000], Loss: 6.1055\n",
      "Epoch [1593/3000], Loss: 6.1019\n",
      "Epoch [1594/3000], Loss: 6.0984\n",
      "Epoch [1595/3000], Loss: 6.0948\n",
      "Epoch [1596/3000], Loss: 6.0912\n",
      "Epoch [1597/3000], Loss: 6.0877\n",
      "Epoch [1598/3000], Loss: 6.0841\n",
      "Epoch [1599/3000], Loss: 6.0806\n",
      "Epoch [1600/3000], Loss: 6.0770\n",
      "Epoch [1601/3000], Loss: 6.0735\n",
      "Epoch [1602/3000], Loss: 6.0700\n",
      "Epoch [1603/3000], Loss: 6.0664\n",
      "Epoch [1604/3000], Loss: 6.0629\n",
      "Epoch [1605/3000], Loss: 6.0594\n",
      "Epoch [1606/3000], Loss: 6.0559\n",
      "Epoch [1607/3000], Loss: 6.0525\n",
      "Epoch [1608/3000], Loss: 6.0490\n",
      "Epoch [1609/3000], Loss: 6.0456\n",
      "Epoch [1610/3000], Loss: 6.0422\n",
      "Epoch [1611/3000], Loss: 6.0388\n",
      "Epoch [1612/3000], Loss: 6.0353\n",
      "Epoch [1613/3000], Loss: 6.0319\n",
      "Epoch [1614/3000], Loss: 6.0283\n",
      "Epoch [1615/3000], Loss: 6.0247\n",
      "Epoch [1616/3000], Loss: 6.0210\n",
      "Epoch [1617/3000], Loss: 6.0174\n",
      "Epoch [1618/3000], Loss: 6.0137\n",
      "Epoch [1619/3000], Loss: 6.0100\n",
      "Epoch [1620/3000], Loss: 6.0064\n",
      "Epoch [1621/3000], Loss: 6.0029\n",
      "Epoch [1622/3000], Loss: 5.9995\n",
      "Epoch [1623/3000], Loss: 5.9961\n",
      "Epoch [1624/3000], Loss: 5.9927\n",
      "Epoch [1625/3000], Loss: 5.9893\n",
      "Epoch [1626/3000], Loss: 5.9859\n",
      "Epoch [1627/3000], Loss: 5.9824\n",
      "Epoch [1628/3000], Loss: 5.9788\n",
      "Epoch [1629/3000], Loss: 5.9753\n",
      "Epoch [1630/3000], Loss: 5.9718\n",
      "Epoch [1631/3000], Loss: 5.9683\n",
      "Epoch [1632/3000], Loss: 5.9649\n",
      "Epoch [1633/3000], Loss: 5.9615\n",
      "Epoch [1634/3000], Loss: 5.9581\n",
      "Epoch [1635/3000], Loss: 5.9547\n",
      "Epoch [1636/3000], Loss: 5.9513\n",
      "Epoch [1637/3000], Loss: 5.9479\n",
      "Epoch [1638/3000], Loss: 5.9444\n",
      "Epoch [1639/3000], Loss: 5.9410\n",
      "Epoch [1640/3000], Loss: 5.9375\n",
      "Epoch [1641/3000], Loss: 5.9341\n",
      "Epoch [1642/3000], Loss: 5.9307\n",
      "Epoch [1643/3000], Loss: 5.9273\n",
      "Epoch [1644/3000], Loss: 5.9239\n",
      "Epoch [1645/3000], Loss: 5.9205\n",
      "Epoch [1646/3000], Loss: 5.9172\n",
      "Epoch [1647/3000], Loss: 5.9138\n",
      "Epoch [1648/3000], Loss: 5.9105\n",
      "Epoch [1649/3000], Loss: 5.9072\n",
      "Epoch [1650/3000], Loss: 5.9038\n",
      "Epoch [1651/3000], Loss: 5.9005\n",
      "Epoch [1652/3000], Loss: 5.8972\n",
      "Epoch [1653/3000], Loss: 5.8939\n",
      "Epoch [1654/3000], Loss: 5.8905\n",
      "Epoch [1655/3000], Loss: 5.8872\n",
      "Epoch [1656/3000], Loss: 5.8838\n",
      "Epoch [1657/3000], Loss: 5.8803\n",
      "Epoch [1658/3000], Loss: 5.8769\n",
      "Epoch [1659/3000], Loss: 5.8735\n",
      "Epoch [1660/3000], Loss: 5.8701\n",
      "Epoch [1661/3000], Loss: 5.8667\n",
      "Epoch [1662/3000], Loss: 5.8634\n",
      "Epoch [1663/3000], Loss: 5.8600\n",
      "Epoch [1664/3000], Loss: 5.8567\n",
      "Epoch [1665/3000], Loss: 5.8534\n",
      "Epoch [1666/3000], Loss: 5.8500\n",
      "Epoch [1667/3000], Loss: 5.8467\n",
      "Epoch [1668/3000], Loss: 5.8434\n",
      "Epoch [1669/3000], Loss: 5.8400\n",
      "Epoch [1670/3000], Loss: 5.8368\n",
      "Epoch [1671/3000], Loss: 5.8334\n",
      "Epoch [1672/3000], Loss: 5.8301\n",
      "Epoch [1673/3000], Loss: 5.8268\n",
      "Epoch [1674/3000], Loss: 5.8234\n",
      "Epoch [1675/3000], Loss: 5.8201\n",
      "Epoch [1676/3000], Loss: 5.8168\n",
      "Epoch [1677/3000], Loss: 5.8134\n",
      "Epoch [1678/3000], Loss: 5.8101\n",
      "Epoch [1679/3000], Loss: 5.8067\n",
      "Epoch [1680/3000], Loss: 5.8034\n",
      "Epoch [1681/3000], Loss: 5.8001\n",
      "Epoch [1682/3000], Loss: 5.7968\n",
      "Epoch [1683/3000], Loss: 5.7935\n",
      "Epoch [1684/3000], Loss: 5.7902\n",
      "Epoch [1685/3000], Loss: 5.7869\n",
      "Epoch [1686/3000], Loss: 5.7836\n",
      "Epoch [1687/3000], Loss: 5.7804\n",
      "Epoch [1688/3000], Loss: 5.7772\n",
      "Epoch [1689/3000], Loss: 5.7739\n",
      "Epoch [1690/3000], Loss: 5.7707\n",
      "Epoch [1691/3000], Loss: 5.7673\n",
      "Epoch [1692/3000], Loss: 5.7640\n",
      "Epoch [1693/3000], Loss: 5.7606\n",
      "Epoch [1694/3000], Loss: 5.7571\n",
      "Epoch [1695/3000], Loss: 5.7537\n",
      "Epoch [1696/3000], Loss: 5.7502\n",
      "Epoch [1697/3000], Loss: 5.7469\n",
      "Epoch [1698/3000], Loss: 5.7435\n",
      "Epoch [1699/3000], Loss: 5.7402\n",
      "Epoch [1700/3000], Loss: 5.7369\n",
      "Epoch [1701/3000], Loss: 5.7337\n",
      "Epoch [1702/3000], Loss: 5.7304\n",
      "Epoch [1703/3000], Loss: 5.7271\n",
      "Epoch [1704/3000], Loss: 5.7239\n",
      "Epoch [1705/3000], Loss: 5.7206\n",
      "Epoch [1706/3000], Loss: 5.7173\n",
      "Epoch [1707/3000], Loss: 5.7140\n",
      "Epoch [1708/3000], Loss: 5.7107\n",
      "Epoch [1709/3000], Loss: 5.7073\n",
      "Epoch [1710/3000], Loss: 5.7040\n",
      "Epoch [1711/3000], Loss: 5.7006\n",
      "Epoch [1712/3000], Loss: 5.6972\n",
      "Epoch [1713/3000], Loss: 5.6938\n",
      "Epoch [1714/3000], Loss: 5.6905\n",
      "Epoch [1715/3000], Loss: 5.6871\n",
      "Epoch [1716/3000], Loss: 5.6838\n",
      "Epoch [1717/3000], Loss: 5.6805\n",
      "Epoch [1718/3000], Loss: 5.6772\n",
      "Epoch [1719/3000], Loss: 5.6739\n",
      "Epoch [1720/3000], Loss: 5.6706\n",
      "Epoch [1721/3000], Loss: 5.6673\n",
      "Epoch [1722/3000], Loss: 5.6641\n",
      "Epoch [1723/3000], Loss: 5.6609\n",
      "Epoch [1724/3000], Loss: 5.6577\n",
      "Epoch [1725/3000], Loss: 5.6545\n",
      "Epoch [1726/3000], Loss: 5.6513\n",
      "Epoch [1727/3000], Loss: 5.6480\n",
      "Epoch [1728/3000], Loss: 5.6447\n",
      "Epoch [1729/3000], Loss: 5.6413\n",
      "Epoch [1730/3000], Loss: 5.6379\n",
      "Epoch [1731/3000], Loss: 5.6344\n",
      "Epoch [1732/3000], Loss: 5.6309\n",
      "Epoch [1733/3000], Loss: 5.6274\n",
      "Epoch [1734/3000], Loss: 5.6240\n",
      "Epoch [1735/3000], Loss: 5.6207\n",
      "Epoch [1736/3000], Loss: 5.6174\n",
      "Epoch [1737/3000], Loss: 5.6142\n",
      "Epoch [1738/3000], Loss: 5.6110\n",
      "Epoch [1739/3000], Loss: 5.6077\n",
      "Epoch [1740/3000], Loss: 5.6045\n",
      "Epoch [1741/3000], Loss: 5.6012\n",
      "Epoch [1742/3000], Loss: 5.5979\n",
      "Epoch [1743/3000], Loss: 5.5947\n",
      "Epoch [1744/3000], Loss: 5.5914\n",
      "Epoch [1745/3000], Loss: 5.5880\n",
      "Epoch [1746/3000], Loss: 5.5847\n",
      "Epoch [1747/3000], Loss: 5.5813\n",
      "Epoch [1748/3000], Loss: 5.5780\n",
      "Epoch [1749/3000], Loss: 5.5747\n",
      "Epoch [1750/3000], Loss: 5.5715\n",
      "Epoch [1751/3000], Loss: 5.5682\n",
      "Epoch [1752/3000], Loss: 5.5650\n",
      "Epoch [1753/3000], Loss: 5.5618\n",
      "Epoch [1754/3000], Loss: 5.5586\n",
      "Epoch [1755/3000], Loss: 5.5555\n",
      "Epoch [1756/3000], Loss: 5.5523\n",
      "Epoch [1757/3000], Loss: 5.5492\n",
      "Epoch [1758/3000], Loss: 5.5461\n",
      "Epoch [1759/3000], Loss: 5.5430\n",
      "Epoch [1760/3000], Loss: 5.5400\n",
      "Epoch [1761/3000], Loss: 5.5369\n",
      "Epoch [1762/3000], Loss: 5.5339\n",
      "Epoch [1763/3000], Loss: 5.5309\n",
      "Epoch [1764/3000], Loss: 5.5278\n",
      "Epoch [1765/3000], Loss: 5.5248\n",
      "Epoch [1766/3000], Loss: 5.5218\n",
      "Epoch [1767/3000], Loss: 5.5187\n",
      "Epoch [1768/3000], Loss: 5.5157\n",
      "Epoch [1769/3000], Loss: 5.5126\n",
      "Epoch [1770/3000], Loss: 5.5096\n",
      "Epoch [1771/3000], Loss: 5.5065\n",
      "Epoch [1772/3000], Loss: 5.5036\n",
      "Epoch [1773/3000], Loss: 5.5006\n",
      "Epoch [1774/3000], Loss: 5.4976\n",
      "Epoch [1775/3000], Loss: 5.4947\n",
      "Epoch [1776/3000], Loss: 5.4918\n",
      "Epoch [1777/3000], Loss: 5.4889\n",
      "Epoch [1778/3000], Loss: 5.4861\n",
      "Epoch [1779/3000], Loss: 5.4832\n",
      "Epoch [1780/3000], Loss: 5.4803\n",
      "Epoch [1781/3000], Loss: 5.4775\n",
      "Epoch [1782/3000], Loss: 5.4747\n",
      "Epoch [1783/3000], Loss: 5.4720\n",
      "Epoch [1784/3000], Loss: 5.4693\n",
      "Epoch [1785/3000], Loss: 5.4665\n",
      "Epoch [1786/3000], Loss: 5.4638\n",
      "Epoch [1787/3000], Loss: 5.4609\n",
      "Epoch [1788/3000], Loss: 5.4580\n",
      "Epoch [1789/3000], Loss: 5.4551\n",
      "Epoch [1790/3000], Loss: 5.4521\n",
      "Epoch [1791/3000], Loss: 5.4492\n",
      "Epoch [1792/3000], Loss: 5.4462\n",
      "Epoch [1793/3000], Loss: 5.4433\n",
      "Epoch [1794/3000], Loss: 5.4404\n",
      "Epoch [1795/3000], Loss: 5.4376\n",
      "Epoch [1796/3000], Loss: 5.4348\n",
      "Epoch [1797/3000], Loss: 5.4320\n",
      "Epoch [1798/3000], Loss: 5.4292\n",
      "Epoch [1799/3000], Loss: 5.4265\n",
      "Epoch [1800/3000], Loss: 5.4237\n",
      "Epoch [1801/3000], Loss: 5.4209\n",
      "Epoch [1802/3000], Loss: 5.4181\n",
      "Epoch [1803/3000], Loss: 5.4153\n",
      "Epoch [1804/3000], Loss: 5.4125\n",
      "Epoch [1805/3000], Loss: 5.4097\n",
      "Epoch [1806/3000], Loss: 5.4068\n",
      "Epoch [1807/3000], Loss: 5.4040\n",
      "Epoch [1808/3000], Loss: 5.4012\n",
      "Epoch [1809/3000], Loss: 5.3984\n",
      "Epoch [1810/3000], Loss: 5.3957\n",
      "Epoch [1811/3000], Loss: 5.3929\n",
      "Epoch [1812/3000], Loss: 5.3902\n",
      "Epoch [1813/3000], Loss: 5.3874\n",
      "Epoch [1814/3000], Loss: 5.3847\n",
      "Epoch [1815/3000], Loss: 5.3820\n",
      "Epoch [1816/3000], Loss: 5.3792\n",
      "Epoch [1817/3000], Loss: 5.3765\n",
      "Epoch [1818/3000], Loss: 5.3738\n",
      "Epoch [1819/3000], Loss: 5.3710\n",
      "Epoch [1820/3000], Loss: 5.3683\n",
      "Epoch [1821/3000], Loss: 5.3656\n",
      "Epoch [1822/3000], Loss: 5.3628\n",
      "Epoch [1823/3000], Loss: 5.3601\n",
      "Epoch [1824/3000], Loss: 5.3573\n",
      "Epoch [1825/3000], Loss: 5.3546\n",
      "Epoch [1826/3000], Loss: 5.3519\n",
      "Epoch [1827/3000], Loss: 5.3492\n",
      "Epoch [1828/3000], Loss: 5.3465\n",
      "Epoch [1829/3000], Loss: 5.3438\n",
      "Epoch [1830/3000], Loss: 5.3411\n",
      "Epoch [1831/3000], Loss: 5.3384\n",
      "Epoch [1832/3000], Loss: 5.3357\n",
      "Epoch [1833/3000], Loss: 5.3331\n",
      "Epoch [1834/3000], Loss: 5.3304\n",
      "Epoch [1835/3000], Loss: 5.3277\n",
      "Epoch [1836/3000], Loss: 5.3251\n",
      "Epoch [1837/3000], Loss: 5.3224\n",
      "Epoch [1838/3000], Loss: 5.3198\n",
      "Epoch [1839/3000], Loss: 5.3171\n",
      "Epoch [1840/3000], Loss: 5.3145\n",
      "Epoch [1841/3000], Loss: 5.3119\n",
      "Epoch [1842/3000], Loss: 5.3093\n",
      "Epoch [1843/3000], Loss: 5.3066\n",
      "Epoch [1844/3000], Loss: 5.3041\n",
      "Epoch [1845/3000], Loss: 5.3015\n",
      "Epoch [1846/3000], Loss: 5.2990\n",
      "Epoch [1847/3000], Loss: 5.2964\n",
      "Epoch [1848/3000], Loss: 5.2938\n",
      "Epoch [1849/3000], Loss: 5.2913\n",
      "Epoch [1850/3000], Loss: 5.2887\n",
      "Epoch [1851/3000], Loss: 5.2861\n",
      "Epoch [1852/3000], Loss: 5.2835\n",
      "Epoch [1853/3000], Loss: 5.2808\n",
      "Epoch [1854/3000], Loss: 5.2781\n",
      "Epoch [1855/3000], Loss: 5.2754\n",
      "Epoch [1856/3000], Loss: 5.2727\n",
      "Epoch [1857/3000], Loss: 5.2700\n",
      "Epoch [1858/3000], Loss: 5.2674\n",
      "Epoch [1859/3000], Loss: 5.2648\n",
      "Epoch [1860/3000], Loss: 5.2622\n",
      "Epoch [1861/3000], Loss: 5.2596\n",
      "Epoch [1862/3000], Loss: 5.2571\n",
      "Epoch [1863/3000], Loss: 5.2546\n",
      "Epoch [1864/3000], Loss: 5.2521\n",
      "Epoch [1865/3000], Loss: 5.2495\n",
      "Epoch [1866/3000], Loss: 5.2470\n",
      "Epoch [1867/3000], Loss: 5.2444\n",
      "Epoch [1868/3000], Loss: 5.2418\n",
      "Epoch [1869/3000], Loss: 5.2391\n",
      "Epoch [1870/3000], Loss: 5.2365\n",
      "Epoch [1871/3000], Loss: 5.2338\n",
      "Epoch [1872/3000], Loss: 5.2312\n",
      "Epoch [1873/3000], Loss: 5.2286\n",
      "Epoch [1874/3000], Loss: 5.2260\n",
      "Epoch [1875/3000], Loss: 5.2234\n",
      "Epoch [1876/3000], Loss: 5.2208\n",
      "Epoch [1877/3000], Loss: 5.2182\n",
      "Epoch [1878/3000], Loss: 5.2157\n",
      "Epoch [1879/3000], Loss: 5.2131\n",
      "Epoch [1880/3000], Loss: 5.2106\n",
      "Epoch [1881/3000], Loss: 5.2080\n",
      "Epoch [1882/3000], Loss: 5.2055\n",
      "Epoch [1883/3000], Loss: 5.2030\n",
      "Epoch [1884/3000], Loss: 5.2006\n",
      "Epoch [1885/3000], Loss: 5.1981\n",
      "Epoch [1886/3000], Loss: 5.1957\n",
      "Epoch [1887/3000], Loss: 5.1932\n",
      "Epoch [1888/3000], Loss: 5.1908\n",
      "Epoch [1889/3000], Loss: 5.1882\n",
      "Epoch [1890/3000], Loss: 5.1856\n",
      "Epoch [1891/3000], Loss: 5.1830\n",
      "Epoch [1892/3000], Loss: 5.1802\n",
      "Epoch [1893/3000], Loss: 5.1774\n",
      "Epoch [1894/3000], Loss: 5.1747\n",
      "Epoch [1895/3000], Loss: 5.1720\n",
      "Epoch [1896/3000], Loss: 5.1693\n",
      "Epoch [1897/3000], Loss: 5.1668\n",
      "Epoch [1898/3000], Loss: 5.1643\n",
      "Epoch [1899/3000], Loss: 5.1618\n",
      "Epoch [1900/3000], Loss: 5.1594\n",
      "Epoch [1901/3000], Loss: 5.1569\n",
      "Epoch [1902/3000], Loss: 5.1544\n",
      "Epoch [1903/3000], Loss: 5.1518\n",
      "Epoch [1904/3000], Loss: 5.1492\n",
      "Epoch [1905/3000], Loss: 5.1466\n",
      "Epoch [1906/3000], Loss: 5.1440\n",
      "Epoch [1907/3000], Loss: 5.1415\n",
      "Epoch [1908/3000], Loss: 5.1389\n",
      "Epoch [1909/3000], Loss: 5.1364\n",
      "Epoch [1910/3000], Loss: 5.1340\n",
      "Epoch [1911/3000], Loss: 5.1315\n",
      "Epoch [1912/3000], Loss: 5.1291\n",
      "Epoch [1913/3000], Loss: 5.1266\n",
      "Epoch [1914/3000], Loss: 5.1242\n",
      "Epoch [1915/3000], Loss: 5.1218\n",
      "Epoch [1916/3000], Loss: 5.1193\n",
      "Epoch [1917/3000], Loss: 5.1169\n",
      "Epoch [1918/3000], Loss: 5.1144\n",
      "Epoch [1919/3000], Loss: 5.1119\n",
      "Epoch [1920/3000], Loss: 5.1095\n",
      "Epoch [1921/3000], Loss: 5.1070\n",
      "Epoch [1922/3000], Loss: 5.1045\n",
      "Epoch [1923/3000], Loss: 5.1021\n",
      "Epoch [1924/3000], Loss: 5.0996\n",
      "Epoch [1925/3000], Loss: 5.0972\n",
      "Epoch [1926/3000], Loss: 5.0948\n",
      "Epoch [1927/3000], Loss: 5.0924\n",
      "Epoch [1928/3000], Loss: 5.0900\n",
      "Epoch [1929/3000], Loss: 5.0876\n",
      "Epoch [1930/3000], Loss: 5.0851\n",
      "Epoch [1931/3000], Loss: 5.0828\n",
      "Epoch [1932/3000], Loss: 5.0804\n",
      "Epoch [1933/3000], Loss: 5.0780\n",
      "Epoch [1934/3000], Loss: 5.0756\n",
      "Epoch [1935/3000], Loss: 5.0732\n",
      "Epoch [1936/3000], Loss: 5.0709\n",
      "Epoch [1937/3000], Loss: 5.0685\n",
      "Epoch [1938/3000], Loss: 5.0662\n",
      "Epoch [1939/3000], Loss: 5.0639\n",
      "Epoch [1940/3000], Loss: 5.0617\n",
      "Epoch [1941/3000], Loss: 5.0594\n",
      "Epoch [1942/3000], Loss: 5.0572\n",
      "Epoch [1943/3000], Loss: 5.0551\n",
      "Epoch [1944/3000], Loss: 5.0530\n",
      "Epoch [1945/3000], Loss: 5.0509\n",
      "Epoch [1946/3000], Loss: 5.0489\n",
      "Epoch [1947/3000], Loss: 5.0467\n",
      "Epoch [1948/3000], Loss: 5.0444\n",
      "Epoch [1949/3000], Loss: 5.0419\n",
      "Epoch [1950/3000], Loss: 5.0393\n",
      "Epoch [1951/3000], Loss: 5.0366\n",
      "Epoch [1952/3000], Loss: 5.0340\n",
      "Epoch [1953/3000], Loss: 5.0315\n",
      "Epoch [1954/3000], Loss: 5.0291\n",
      "Epoch [1955/3000], Loss: 5.0269\n",
      "Epoch [1956/3000], Loss: 5.0248\n",
      "Epoch [1957/3000], Loss: 5.0226\n",
      "Epoch [1958/3000], Loss: 5.0204\n",
      "Epoch [1959/3000], Loss: 5.0182\n",
      "Epoch [1960/3000], Loss: 5.0158\n",
      "Epoch [1961/3000], Loss: 5.0135\n",
      "Epoch [1962/3000], Loss: 5.0111\n",
      "Epoch [1963/3000], Loss: 5.0088\n",
      "Epoch [1964/3000], Loss: 5.0065\n",
      "Epoch [1965/3000], Loss: 5.0043\n",
      "Epoch [1966/3000], Loss: 5.0021\n",
      "Epoch [1967/3000], Loss: 4.9999\n",
      "Epoch [1968/3000], Loss: 4.9977\n",
      "Epoch [1969/3000], Loss: 4.9955\n",
      "Epoch [1970/3000], Loss: 4.9933\n",
      "Epoch [1971/3000], Loss: 4.9910\n",
      "Epoch [1972/3000], Loss: 4.9887\n",
      "Epoch [1973/3000], Loss: 4.9864\n",
      "Epoch [1974/3000], Loss: 4.9841\n",
      "Epoch [1975/3000], Loss: 4.9819\n",
      "Epoch [1976/3000], Loss: 4.9797\n",
      "Epoch [1977/3000], Loss: 4.9775\n",
      "Epoch [1978/3000], Loss: 4.9753\n",
      "Epoch [1979/3000], Loss: 4.9731\n",
      "Epoch [1980/3000], Loss: 4.9709\n",
      "Epoch [1981/3000], Loss: 4.9686\n",
      "Epoch [1982/3000], Loss: 4.9664\n",
      "Epoch [1983/3000], Loss: 4.9642\n",
      "Epoch [1984/3000], Loss: 4.9619\n",
      "Epoch [1985/3000], Loss: 4.9597\n",
      "Epoch [1986/3000], Loss: 4.9575\n",
      "Epoch [1987/3000], Loss: 4.9553\n",
      "Epoch [1988/3000], Loss: 4.9531\n",
      "Epoch [1989/3000], Loss: 4.9509\n",
      "Epoch [1990/3000], Loss: 4.9488\n",
      "Epoch [1991/3000], Loss: 4.9466\n",
      "Epoch [1992/3000], Loss: 4.9444\n",
      "Epoch [1993/3000], Loss: 4.9422\n",
      "Epoch [1994/3000], Loss: 4.9400\n",
      "Epoch [1995/3000], Loss: 4.9379\n",
      "Epoch [1996/3000], Loss: 4.9357\n",
      "Epoch [1997/3000], Loss: 4.9335\n",
      "Epoch [1998/3000], Loss: 4.9313\n",
      "Epoch [1999/3000], Loss: 4.9291\n",
      "Epoch [2000/3000], Loss: 4.9270\n",
      "Epoch [2001/3000], Loss: 4.9248\n",
      "Epoch [2002/3000], Loss: 4.9226\n",
      "Epoch [2003/3000], Loss: 4.9205\n",
      "Epoch [2004/3000], Loss: 4.9183\n",
      "Epoch [2005/3000], Loss: 4.9162\n",
      "Epoch [2006/3000], Loss: 4.9140\n",
      "Epoch [2007/3000], Loss: 4.9119\n",
      "Epoch [2008/3000], Loss: 4.9098\n",
      "Epoch [2009/3000], Loss: 4.9077\n",
      "Epoch [2010/3000], Loss: 4.9057\n",
      "Epoch [2011/3000], Loss: 4.9037\n",
      "Epoch [2012/3000], Loss: 4.9018\n",
      "Epoch [2013/3000], Loss: 4.8998\n",
      "Epoch [2014/3000], Loss: 4.8979\n",
      "Epoch [2015/3000], Loss: 4.8959\n",
      "Epoch [2016/3000], Loss: 4.8938\n",
      "Epoch [2017/3000], Loss: 4.8916\n",
      "Epoch [2018/3000], Loss: 4.8892\n",
      "Epoch [2019/3000], Loss: 4.8866\n",
      "Epoch [2020/3000], Loss: 4.8841\n",
      "Epoch [2021/3000], Loss: 4.8817\n",
      "Epoch [2022/3000], Loss: 4.8794\n",
      "Epoch [2023/3000], Loss: 4.8773\n",
      "Epoch [2024/3000], Loss: 4.8753\n",
      "Epoch [2025/3000], Loss: 4.8734\n",
      "Epoch [2026/3000], Loss: 4.8715\n",
      "Epoch [2027/3000], Loss: 4.8694\n",
      "Epoch [2028/3000], Loss: 4.8673\n",
      "Epoch [2029/3000], Loss: 4.8651\n",
      "Epoch [2030/3000], Loss: 4.8629\n",
      "Epoch [2031/3000], Loss: 4.8606\n",
      "Epoch [2032/3000], Loss: 4.8584\n",
      "Epoch [2033/3000], Loss: 4.8563\n",
      "Epoch [2034/3000], Loss: 4.8542\n",
      "Epoch [2035/3000], Loss: 4.8522\n",
      "Epoch [2036/3000], Loss: 4.8502\n",
      "Epoch [2037/3000], Loss: 4.8481\n",
      "Epoch [2038/3000], Loss: 4.8461\n",
      "Epoch [2039/3000], Loss: 4.8441\n",
      "Epoch [2040/3000], Loss: 4.8420\n",
      "Epoch [2041/3000], Loss: 4.8399\n",
      "Epoch [2042/3000], Loss: 4.8377\n",
      "Epoch [2043/3000], Loss: 4.8356\n",
      "Epoch [2044/3000], Loss: 4.8335\n",
      "Epoch [2045/3000], Loss: 4.8315\n",
      "Epoch [2046/3000], Loss: 4.8294\n",
      "Epoch [2047/3000], Loss: 4.8274\n",
      "Epoch [2048/3000], Loss: 4.8254\n",
      "Epoch [2049/3000], Loss: 4.8234\n",
      "Epoch [2050/3000], Loss: 4.8213\n",
      "Epoch [2051/3000], Loss: 4.8193\n",
      "Epoch [2052/3000], Loss: 4.8172\n",
      "Epoch [2053/3000], Loss: 4.8152\n",
      "Epoch [2054/3000], Loss: 4.8132\n",
      "Epoch [2055/3000], Loss: 4.8111\n",
      "Epoch [2056/3000], Loss: 4.8091\n",
      "Epoch [2057/3000], Loss: 4.8071\n",
      "Epoch [2058/3000], Loss: 4.8051\n",
      "Epoch [2059/3000], Loss: 4.8031\n",
      "Epoch [2060/3000], Loss: 4.8011\n",
      "Epoch [2061/3000], Loss: 4.7991\n",
      "Epoch [2062/3000], Loss: 4.7971\n",
      "Epoch [2063/3000], Loss: 4.7951\n",
      "Epoch [2064/3000], Loss: 4.7931\n",
      "Epoch [2065/3000], Loss: 4.7911\n",
      "Epoch [2066/3000], Loss: 4.7891\n",
      "Epoch [2067/3000], Loss: 4.7871\n",
      "Epoch [2068/3000], Loss: 4.7851\n",
      "Epoch [2069/3000], Loss: 4.7831\n",
      "Epoch [2070/3000], Loss: 4.7811\n",
      "Epoch [2071/3000], Loss: 4.7791\n",
      "Epoch [2072/3000], Loss: 4.7771\n",
      "Epoch [2073/3000], Loss: 4.7751\n",
      "Epoch [2074/3000], Loss: 4.7732\n",
      "Epoch [2075/3000], Loss: 4.7712\n",
      "Epoch [2076/3000], Loss: 4.7692\n",
      "Epoch [2077/3000], Loss: 4.7672\n",
      "Epoch [2078/3000], Loss: 4.7652\n",
      "Epoch [2079/3000], Loss: 4.7632\n",
      "Epoch [2080/3000], Loss: 4.7612\n",
      "Epoch [2081/3000], Loss: 4.7592\n",
      "Epoch [2082/3000], Loss: 4.7572\n",
      "Epoch [2083/3000], Loss: 4.7551\n",
      "Epoch [2084/3000], Loss: 4.7531\n",
      "Epoch [2085/3000], Loss: 4.7511\n",
      "Epoch [2086/3000], Loss: 4.7491\n",
      "Epoch [2087/3000], Loss: 4.7472\n",
      "Epoch [2088/3000], Loss: 4.7452\n",
      "Epoch [2089/3000], Loss: 4.7432\n",
      "Epoch [2090/3000], Loss: 4.7412\n",
      "Epoch [2091/3000], Loss: 4.7392\n",
      "Epoch [2092/3000], Loss: 4.7373\n",
      "Epoch [2093/3000], Loss: 4.7353\n",
      "Epoch [2094/3000], Loss: 4.7334\n",
      "Epoch [2095/3000], Loss: 4.7314\n",
      "Epoch [2096/3000], Loss: 4.7295\n",
      "Epoch [2097/3000], Loss: 4.7276\n",
      "Epoch [2098/3000], Loss: 4.7257\n",
      "Epoch [2099/3000], Loss: 4.7238\n",
      "Epoch [2100/3000], Loss: 4.7220\n",
      "Epoch [2101/3000], Loss: 4.7202\n",
      "Epoch [2102/3000], Loss: 4.7184\n",
      "Epoch [2103/3000], Loss: 4.7167\n",
      "Epoch [2104/3000], Loss: 4.7151\n",
      "Epoch [2105/3000], Loss: 4.7134\n",
      "Epoch [2106/3000], Loss: 4.7118\n",
      "Epoch [2107/3000], Loss: 4.7101\n",
      "Epoch [2108/3000], Loss: 4.7083\n",
      "Epoch [2109/3000], Loss: 4.7063\n",
      "Epoch [2110/3000], Loss: 4.7041\n",
      "Epoch [2111/3000], Loss: 4.7016\n",
      "Epoch [2112/3000], Loss: 4.6991\n",
      "Epoch [2113/3000], Loss: 4.6968\n",
      "Epoch [2114/3000], Loss: 4.6947\n",
      "Epoch [2115/3000], Loss: 4.6929\n",
      "Epoch [2116/3000], Loss: 4.6912\n",
      "Epoch [2117/3000], Loss: 4.6896\n",
      "Epoch [2118/3000], Loss: 4.6878\n",
      "Epoch [2119/3000], Loss: 4.6859\n",
      "Epoch [2120/3000], Loss: 4.6839\n",
      "Epoch [2121/3000], Loss: 4.6818\n",
      "Epoch [2122/3000], Loss: 4.6798\n",
      "Epoch [2123/3000], Loss: 4.6778\n",
      "Epoch [2124/3000], Loss: 4.6759\n",
      "Epoch [2125/3000], Loss: 4.6741\n",
      "Epoch [2126/3000], Loss: 4.6723\n",
      "Epoch [2127/3000], Loss: 4.6705\n",
      "Epoch [2128/3000], Loss: 4.6687\n",
      "Epoch [2129/3000], Loss: 4.6669\n",
      "Epoch [2130/3000], Loss: 4.6650\n",
      "Epoch [2131/3000], Loss: 4.6631\n",
      "Epoch [2132/3000], Loss: 4.6612\n",
      "Epoch [2133/3000], Loss: 4.6592\n",
      "Epoch [2134/3000], Loss: 4.6573\n",
      "Epoch [2135/3000], Loss: 4.6554\n",
      "Epoch [2136/3000], Loss: 4.6535\n",
      "Epoch [2137/3000], Loss: 4.6517\n",
      "Epoch [2138/3000], Loss: 4.6499\n",
      "Epoch [2139/3000], Loss: 4.6481\n",
      "Epoch [2140/3000], Loss: 4.6463\n",
      "Epoch [2141/3000], Loss: 4.6445\n",
      "Epoch [2142/3000], Loss: 4.6427\n",
      "Epoch [2143/3000], Loss: 4.6408\n",
      "Epoch [2144/3000], Loss: 4.6390\n",
      "Epoch [2145/3000], Loss: 4.6371\n",
      "Epoch [2146/3000], Loss: 4.6353\n",
      "Epoch [2147/3000], Loss: 4.6334\n",
      "Epoch [2148/3000], Loss: 4.6316\n",
      "Epoch [2149/3000], Loss: 4.6297\n",
      "Epoch [2150/3000], Loss: 4.6279\n",
      "Epoch [2151/3000], Loss: 4.6260\n",
      "Epoch [2152/3000], Loss: 4.6242\n",
      "Epoch [2153/3000], Loss: 4.6224\n",
      "Epoch [2154/3000], Loss: 4.6206\n",
      "Epoch [2155/3000], Loss: 4.6187\n",
      "Epoch [2156/3000], Loss: 4.6169\n",
      "Epoch [2157/3000], Loss: 4.6151\n",
      "Epoch [2158/3000], Loss: 4.6133\n",
      "Epoch [2159/3000], Loss: 4.6115\n",
      "Epoch [2160/3000], Loss: 4.6097\n",
      "Epoch [2161/3000], Loss: 4.6080\n",
      "Epoch [2162/3000], Loss: 4.6062\n",
      "Epoch [2163/3000], Loss: 4.6044\n",
      "Epoch [2164/3000], Loss: 4.6027\n",
      "Epoch [2165/3000], Loss: 4.6009\n",
      "Epoch [2166/3000], Loss: 4.5991\n",
      "Epoch [2167/3000], Loss: 4.5974\n",
      "Epoch [2168/3000], Loss: 4.5956\n",
      "Epoch [2169/3000], Loss: 4.5939\n",
      "Epoch [2170/3000], Loss: 4.5921\n",
      "Epoch [2171/3000], Loss: 4.5903\n",
      "Epoch [2172/3000], Loss: 4.5885\n",
      "Epoch [2173/3000], Loss: 4.5866\n",
      "Epoch [2174/3000], Loss: 4.5848\n",
      "Epoch [2175/3000], Loss: 4.5829\n",
      "Epoch [2176/3000], Loss: 4.5811\n",
      "Epoch [2177/3000], Loss: 4.5793\n",
      "Epoch [2178/3000], Loss: 4.5774\n",
      "Epoch [2179/3000], Loss: 4.5756\n",
      "Epoch [2180/3000], Loss: 4.5738\n",
      "Epoch [2181/3000], Loss: 4.5720\n",
      "Epoch [2182/3000], Loss: 4.5703\n",
      "Epoch [2183/3000], Loss: 4.5685\n",
      "Epoch [2184/3000], Loss: 4.5667\n",
      "Epoch [2185/3000], Loss: 4.5649\n",
      "Epoch [2186/3000], Loss: 4.5631\n",
      "Epoch [2187/3000], Loss: 4.5614\n",
      "Epoch [2188/3000], Loss: 4.5596\n",
      "Epoch [2189/3000], Loss: 4.5578\n",
      "Epoch [2190/3000], Loss: 4.5560\n",
      "Epoch [2191/3000], Loss: 4.5543\n",
      "Epoch [2192/3000], Loss: 4.5525\n",
      "Epoch [2193/3000], Loss: 4.5508\n",
      "Epoch [2194/3000], Loss: 4.5490\n",
      "Epoch [2195/3000], Loss: 4.5473\n",
      "Epoch [2196/3000], Loss: 4.5456\n",
      "Epoch [2197/3000], Loss: 4.5438\n",
      "Epoch [2198/3000], Loss: 4.5421\n",
      "Epoch [2199/3000], Loss: 4.5405\n",
      "Epoch [2200/3000], Loss: 4.5388\n",
      "Epoch [2201/3000], Loss: 4.5371\n",
      "Epoch [2202/3000], Loss: 4.5354\n",
      "Epoch [2203/3000], Loss: 4.5337\n",
      "Epoch [2204/3000], Loss: 4.5320\n",
      "Epoch [2205/3000], Loss: 4.5303\n",
      "Epoch [2206/3000], Loss: 4.5287\n",
      "Epoch [2207/3000], Loss: 4.5270\n",
      "Epoch [2208/3000], Loss: 4.5253\n",
      "Epoch [2209/3000], Loss: 4.5235\n",
      "Epoch [2210/3000], Loss: 4.5217\n",
      "Epoch [2211/3000], Loss: 4.5199\n",
      "Epoch [2212/3000], Loss: 4.5180\n",
      "Epoch [2213/3000], Loss: 4.5162\n",
      "Epoch [2214/3000], Loss: 4.5143\n",
      "Epoch [2215/3000], Loss: 4.5124\n",
      "Epoch [2216/3000], Loss: 4.5106\n",
      "Epoch [2217/3000], Loss: 4.5088\n",
      "Epoch [2218/3000], Loss: 4.5070\n",
      "Epoch [2219/3000], Loss: 4.5052\n",
      "Epoch [2220/3000], Loss: 4.5035\n",
      "Epoch [2221/3000], Loss: 4.5018\n",
      "Epoch [2222/3000], Loss: 4.5001\n",
      "Epoch [2223/3000], Loss: 4.4985\n",
      "Epoch [2224/3000], Loss: 4.4968\n",
      "Epoch [2225/3000], Loss: 4.4952\n",
      "Epoch [2226/3000], Loss: 4.4935\n",
      "Epoch [2227/3000], Loss: 4.4919\n",
      "Epoch [2228/3000], Loss: 4.4902\n",
      "Epoch [2229/3000], Loss: 4.4885\n",
      "Epoch [2230/3000], Loss: 4.4868\n",
      "Epoch [2231/3000], Loss: 4.4850\n",
      "Epoch [2232/3000], Loss: 4.4833\n",
      "Epoch [2233/3000], Loss: 4.4815\n",
      "Epoch [2234/3000], Loss: 4.4797\n",
      "Epoch [2235/3000], Loss: 4.4779\n",
      "Epoch [2236/3000], Loss: 4.4762\n",
      "Epoch [2237/3000], Loss: 4.4744\n",
      "Epoch [2238/3000], Loss: 4.4727\n",
      "Epoch [2239/3000], Loss: 4.4709\n",
      "Epoch [2240/3000], Loss: 4.4692\n",
      "Epoch [2241/3000], Loss: 4.4675\n",
      "Epoch [2242/3000], Loss: 4.4658\n",
      "Epoch [2243/3000], Loss: 4.4641\n",
      "Epoch [2244/3000], Loss: 4.4625\n",
      "Epoch [2245/3000], Loss: 4.4608\n",
      "Epoch [2246/3000], Loss: 4.4591\n",
      "Epoch [2247/3000], Loss: 4.4574\n",
      "Epoch [2248/3000], Loss: 4.4558\n",
      "Epoch [2249/3000], Loss: 4.4541\n",
      "Epoch [2250/3000], Loss: 4.4524\n",
      "Epoch [2251/3000], Loss: 4.4508\n",
      "Epoch [2252/3000], Loss: 4.4491\n",
      "Epoch [2253/3000], Loss: 4.4475\n",
      "Epoch [2254/3000], Loss: 4.4458\n",
      "Epoch [2255/3000], Loss: 4.4442\n",
      "Epoch [2256/3000], Loss: 4.4426\n",
      "Epoch [2257/3000], Loss: 4.4410\n",
      "Epoch [2258/3000], Loss: 4.4394\n",
      "Epoch [2259/3000], Loss: 4.4378\n",
      "Epoch [2260/3000], Loss: 4.4363\n",
      "Epoch [2261/3000], Loss: 4.4347\n",
      "Epoch [2262/3000], Loss: 4.4331\n",
      "Epoch [2263/3000], Loss: 4.4316\n",
      "Epoch [2264/3000], Loss: 4.4299\n",
      "Epoch [2265/3000], Loss: 4.4283\n",
      "Epoch [2266/3000], Loss: 4.4266\n",
      "Epoch [2267/3000], Loss: 4.4249\n",
      "Epoch [2268/3000], Loss: 4.4232\n",
      "Epoch [2269/3000], Loss: 4.4214\n",
      "Epoch [2270/3000], Loss: 4.4196\n",
      "Epoch [2271/3000], Loss: 4.4178\n",
      "Epoch [2272/3000], Loss: 4.4161\n",
      "Epoch [2273/3000], Loss: 4.4144\n",
      "Epoch [2274/3000], Loss: 4.4127\n",
      "Epoch [2275/3000], Loss: 4.4111\n",
      "Epoch [2276/3000], Loss: 4.4095\n",
      "Epoch [2277/3000], Loss: 4.4079\n",
      "Epoch [2278/3000], Loss: 4.4063\n",
      "Epoch [2279/3000], Loss: 4.4048\n",
      "Epoch [2280/3000], Loss: 4.4032\n",
      "Epoch [2281/3000], Loss: 4.4016\n",
      "Epoch [2282/3000], Loss: 4.4001\n",
      "Epoch [2283/3000], Loss: 4.3985\n",
      "Epoch [2284/3000], Loss: 4.3969\n",
      "Epoch [2285/3000], Loss: 4.3953\n",
      "Epoch [2286/3000], Loss: 4.3936\n",
      "Epoch [2287/3000], Loss: 4.3920\n",
      "Epoch [2288/3000], Loss: 4.3904\n",
      "Epoch [2289/3000], Loss: 4.3887\n",
      "Epoch [2290/3000], Loss: 4.3871\n",
      "Epoch [2291/3000], Loss: 4.3854\n",
      "Epoch [2292/3000], Loss: 4.3838\n",
      "Epoch [2293/3000], Loss: 4.3821\n",
      "Epoch [2294/3000], Loss: 4.3805\n",
      "Epoch [2295/3000], Loss: 4.3789\n",
      "Epoch [2296/3000], Loss: 4.3772\n",
      "Epoch [2297/3000], Loss: 4.3756\n",
      "Epoch [2298/3000], Loss: 4.3740\n",
      "Epoch [2299/3000], Loss: 4.3724\n",
      "Epoch [2300/3000], Loss: 4.3708\n",
      "Epoch [2301/3000], Loss: 4.3692\n",
      "Epoch [2302/3000], Loss: 4.3676\n",
      "Epoch [2303/3000], Loss: 4.3660\n",
      "Epoch [2304/3000], Loss: 4.3645\n",
      "Epoch [2305/3000], Loss: 4.3629\n",
      "Epoch [2306/3000], Loss: 4.3614\n",
      "Epoch [2307/3000], Loss: 4.3598\n",
      "Epoch [2308/3000], Loss: 4.3583\n",
      "Epoch [2309/3000], Loss: 4.3569\n",
      "Epoch [2310/3000], Loss: 4.3554\n",
      "Epoch [2311/3000], Loss: 4.3540\n",
      "Epoch [2312/3000], Loss: 4.3526\n",
      "Epoch [2313/3000], Loss: 4.3513\n",
      "Epoch [2314/3000], Loss: 4.3499\n",
      "Epoch [2315/3000], Loss: 4.3485\n",
      "Epoch [2316/3000], Loss: 4.3470\n",
      "Epoch [2317/3000], Loss: 4.3454\n",
      "Epoch [2318/3000], Loss: 4.3437\n",
      "Epoch [2319/3000], Loss: 4.3420\n",
      "Epoch [2320/3000], Loss: 4.3401\n",
      "Epoch [2321/3000], Loss: 4.3383\n",
      "Epoch [2322/3000], Loss: 4.3365\n",
      "Epoch [2323/3000], Loss: 4.3348\n",
      "Epoch [2324/3000], Loss: 4.3332\n",
      "Epoch [2325/3000], Loss: 4.3316\n",
      "Epoch [2326/3000], Loss: 4.3301\n",
      "Epoch [2327/3000], Loss: 4.3286\n",
      "Epoch [2328/3000], Loss: 4.3272\n",
      "Epoch [2329/3000], Loss: 4.3257\n",
      "Epoch [2330/3000], Loss: 4.3242\n",
      "Epoch [2331/3000], Loss: 4.3227\n",
      "Epoch [2332/3000], Loss: 4.3211\n",
      "Epoch [2333/3000], Loss: 4.3196\n",
      "Epoch [2334/3000], Loss: 4.3180\n",
      "Epoch [2335/3000], Loss: 4.3164\n",
      "Epoch [2336/3000], Loss: 4.3148\n",
      "Epoch [2337/3000], Loss: 4.3132\n",
      "Epoch [2338/3000], Loss: 4.3116\n",
      "Epoch [2339/3000], Loss: 4.3101\n",
      "Epoch [2340/3000], Loss: 4.3086\n",
      "Epoch [2341/3000], Loss: 4.3071\n",
      "Epoch [2342/3000], Loss: 4.3056\n",
      "Epoch [2343/3000], Loss: 4.3041\n",
      "Epoch [2344/3000], Loss: 4.3026\n",
      "Epoch [2345/3000], Loss: 4.3011\n",
      "Epoch [2346/3000], Loss: 4.2996\n",
      "Epoch [2347/3000], Loss: 4.2980\n",
      "Epoch [2348/3000], Loss: 4.2965\n",
      "Epoch [2349/3000], Loss: 4.2950\n",
      "Epoch [2350/3000], Loss: 4.2935\n",
      "Epoch [2351/3000], Loss: 4.2920\n",
      "Epoch [2352/3000], Loss: 4.2904\n",
      "Epoch [2353/3000], Loss: 4.2889\n",
      "Epoch [2354/3000], Loss: 4.2874\n",
      "Epoch [2355/3000], Loss: 4.2859\n",
      "Epoch [2356/3000], Loss: 4.2844\n",
      "Epoch [2357/3000], Loss: 4.2829\n",
      "Epoch [2358/3000], Loss: 4.2814\n",
      "Epoch [2359/3000], Loss: 4.2799\n",
      "Epoch [2360/3000], Loss: 4.2784\n",
      "Epoch [2361/3000], Loss: 4.2769\n",
      "Epoch [2362/3000], Loss: 4.2754\n",
      "Epoch [2363/3000], Loss: 4.2739\n",
      "Epoch [2364/3000], Loss: 4.2725\n",
      "Epoch [2365/3000], Loss: 4.2710\n",
      "Epoch [2366/3000], Loss: 4.2695\n",
      "Epoch [2367/3000], Loss: 4.2680\n",
      "Epoch [2368/3000], Loss: 4.2665\n",
      "Epoch [2369/3000], Loss: 4.2650\n",
      "Epoch [2370/3000], Loss: 4.2635\n",
      "Epoch [2371/3000], Loss: 4.2620\n",
      "Epoch [2372/3000], Loss: 4.2606\n",
      "Epoch [2373/3000], Loss: 4.2591\n",
      "Epoch [2374/3000], Loss: 4.2576\n",
      "Epoch [2375/3000], Loss: 4.2562\n",
      "Epoch [2376/3000], Loss: 4.2547\n",
      "Epoch [2377/3000], Loss: 4.2533\n",
      "Epoch [2378/3000], Loss: 4.2519\n",
      "Epoch [2379/3000], Loss: 4.2504\n",
      "Epoch [2380/3000], Loss: 4.2490\n",
      "Epoch [2381/3000], Loss: 4.2476\n",
      "Epoch [2382/3000], Loss: 4.2461\n",
      "Epoch [2383/3000], Loss: 4.2447\n",
      "Epoch [2384/3000], Loss: 4.2433\n",
      "Epoch [2385/3000], Loss: 4.2419\n",
      "Epoch [2386/3000], Loss: 4.2404\n",
      "Epoch [2387/3000], Loss: 4.2390\n",
      "Epoch [2388/3000], Loss: 4.2376\n",
      "Epoch [2389/3000], Loss: 4.2363\n",
      "Epoch [2390/3000], Loss: 4.2349\n",
      "Epoch [2391/3000], Loss: 4.2336\n",
      "Epoch [2392/3000], Loss: 4.2323\n",
      "Epoch [2393/3000], Loss: 4.2310\n",
      "Epoch [2394/3000], Loss: 4.2297\n",
      "Epoch [2395/3000], Loss: 4.2285\n",
      "Epoch [2396/3000], Loss: 4.2272\n",
      "Epoch [2397/3000], Loss: 4.2258\n",
      "Epoch [2398/3000], Loss: 4.2243\n",
      "Epoch [2399/3000], Loss: 4.2226\n",
      "Epoch [2400/3000], Loss: 4.2209\n",
      "Epoch [2401/3000], Loss: 4.2190\n",
      "Epoch [2402/3000], Loss: 4.2172\n",
      "Epoch [2403/3000], Loss: 4.2156\n",
      "Epoch [2404/3000], Loss: 4.2140\n",
      "Epoch [2405/3000], Loss: 4.2126\n",
      "Epoch [2406/3000], Loss: 4.2112\n",
      "Epoch [2407/3000], Loss: 4.2099\n",
      "Epoch [2408/3000], Loss: 4.2086\n",
      "Epoch [2409/3000], Loss: 4.2072\n",
      "Epoch [2410/3000], Loss: 4.2059\n",
      "Epoch [2411/3000], Loss: 4.2045\n",
      "Epoch [2412/3000], Loss: 4.2031\n",
      "Epoch [2413/3000], Loss: 4.2017\n",
      "Epoch [2414/3000], Loss: 4.2002\n",
      "Epoch [2415/3000], Loss: 4.1987\n",
      "Epoch [2416/3000], Loss: 4.1972\n",
      "Epoch [2417/3000], Loss: 4.1958\n",
      "Epoch [2418/3000], Loss: 4.1944\n",
      "Epoch [2419/3000], Loss: 4.1930\n",
      "Epoch [2420/3000], Loss: 4.1917\n",
      "Epoch [2421/3000], Loss: 4.1903\n",
      "Epoch [2422/3000], Loss: 4.1890\n",
      "Epoch [2423/3000], Loss: 4.1876\n",
      "Epoch [2424/3000], Loss: 4.1862\n",
      "Epoch [2425/3000], Loss: 4.1848\n",
      "Epoch [2426/3000], Loss: 4.1834\n",
      "Epoch [2427/3000], Loss: 4.1820\n",
      "Epoch [2428/3000], Loss: 4.1806\n",
      "Epoch [2429/3000], Loss: 4.1792\n",
      "Epoch [2430/3000], Loss: 4.1779\n",
      "Epoch [2431/3000], Loss: 4.1765\n",
      "Epoch [2432/3000], Loss: 4.1752\n",
      "Epoch [2433/3000], Loss: 4.1738\n",
      "Epoch [2434/3000], Loss: 4.1725\n",
      "Epoch [2435/3000], Loss: 4.1711\n",
      "Epoch [2436/3000], Loss: 4.1697\n",
      "Epoch [2437/3000], Loss: 4.1684\n",
      "Epoch [2438/3000], Loss: 4.1670\n",
      "Epoch [2439/3000], Loss: 4.1656\n",
      "Epoch [2440/3000], Loss: 4.1643\n",
      "Epoch [2441/3000], Loss: 4.1629\n",
      "Epoch [2442/3000], Loss: 4.1615\n",
      "Epoch [2443/3000], Loss: 4.1602\n",
      "Epoch [2444/3000], Loss: 4.1588\n",
      "Epoch [2445/3000], Loss: 4.1575\n",
      "Epoch [2446/3000], Loss: 4.1561\n",
      "Epoch [2447/3000], Loss: 4.1548\n",
      "Epoch [2448/3000], Loss: 4.1534\n",
      "Epoch [2449/3000], Loss: 4.1521\n",
      "Epoch [2450/3000], Loss: 4.1507\n",
      "Epoch [2451/3000], Loss: 4.1494\n",
      "Epoch [2452/3000], Loss: 4.1480\n",
      "Epoch [2453/3000], Loss: 4.1467\n",
      "Epoch [2454/3000], Loss: 4.1454\n",
      "Epoch [2455/3000], Loss: 4.1440\n",
      "Epoch [2456/3000], Loss: 4.1427\n",
      "Epoch [2457/3000], Loss: 4.1414\n",
      "Epoch [2458/3000], Loss: 4.1400\n",
      "Epoch [2459/3000], Loss: 4.1387\n",
      "Epoch [2460/3000], Loss: 4.1374\n",
      "Epoch [2461/3000], Loss: 4.1361\n",
      "Epoch [2462/3000], Loss: 4.1347\n",
      "Epoch [2463/3000], Loss: 4.1334\n",
      "Epoch [2464/3000], Loss: 4.1321\n",
      "Epoch [2465/3000], Loss: 4.1309\n",
      "Epoch [2466/3000], Loss: 4.1296\n",
      "Epoch [2467/3000], Loss: 4.1283\n",
      "Epoch [2468/3000], Loss: 4.1271\n",
      "Epoch [2469/3000], Loss: 4.1258\n",
      "Epoch [2470/3000], Loss: 4.1246\n",
      "Epoch [2471/3000], Loss: 4.1234\n",
      "Epoch [2472/3000], Loss: 4.1223\n",
      "Epoch [2473/3000], Loss: 4.1211\n",
      "Epoch [2474/3000], Loss: 4.1200\n",
      "Epoch [2475/3000], Loss: 4.1190\n",
      "Epoch [2476/3000], Loss: 4.1179\n",
      "Epoch [2477/3000], Loss: 4.1169\n",
      "Epoch [2478/3000], Loss: 4.1158\n",
      "Epoch [2479/3000], Loss: 4.1145\n",
      "Epoch [2480/3000], Loss: 4.1131\n",
      "Epoch [2481/3000], Loss: 4.1114\n",
      "Epoch [2482/3000], Loss: 4.1096\n",
      "Epoch [2483/3000], Loss: 4.1077\n",
      "Epoch [2484/3000], Loss: 4.1059\n",
      "Epoch [2485/3000], Loss: 4.1044\n",
      "Epoch [2486/3000], Loss: 4.1031\n",
      "Epoch [2487/3000], Loss: 4.1019\n",
      "Epoch [2488/3000], Loss: 4.1008\n",
      "Epoch [2489/3000], Loss: 4.0997\n",
      "Epoch [2490/3000], Loss: 4.0986\n",
      "Epoch [2491/3000], Loss: 4.0973\n",
      "Epoch [2492/3000], Loss: 4.0959\n",
      "Epoch [2493/3000], Loss: 4.0944\n",
      "Epoch [2494/3000], Loss: 4.0929\n",
      "Epoch [2495/3000], Loss: 4.0915\n",
      "Epoch [2496/3000], Loss: 4.0902\n",
      "Epoch [2497/3000], Loss: 4.0889\n",
      "Epoch [2498/3000], Loss: 4.0877\n",
      "Epoch [2499/3000], Loss: 4.0865\n",
      "Epoch [2500/3000], Loss: 4.0853\n",
      "Epoch [2501/3000], Loss: 4.0841\n",
      "Epoch [2502/3000], Loss: 4.0828\n",
      "Epoch [2503/3000], Loss: 4.0814\n",
      "Epoch [2504/3000], Loss: 4.0801\n",
      "Epoch [2505/3000], Loss: 4.0787\n",
      "Epoch [2506/3000], Loss: 4.0774\n",
      "Epoch [2507/3000], Loss: 4.0761\n",
      "Epoch [2508/3000], Loss: 4.0749\n",
      "Epoch [2509/3000], Loss: 4.0736\n",
      "Epoch [2510/3000], Loss: 4.0724\n",
      "Epoch [2511/3000], Loss: 4.0711\n",
      "Epoch [2512/3000], Loss: 4.0699\n",
      "Epoch [2513/3000], Loss: 4.0686\n",
      "Epoch [2514/3000], Loss: 4.0674\n",
      "Epoch [2515/3000], Loss: 4.0661\n",
      "Epoch [2516/3000], Loss: 4.0648\n",
      "Epoch [2517/3000], Loss: 4.0635\n",
      "Epoch [2518/3000], Loss: 4.0622\n",
      "Epoch [2519/3000], Loss: 4.0610\n",
      "Epoch [2520/3000], Loss: 4.0597\n",
      "Epoch [2521/3000], Loss: 4.0585\n",
      "Epoch [2522/3000], Loss: 4.0573\n",
      "Epoch [2523/3000], Loss: 4.0560\n",
      "Epoch [2524/3000], Loss: 4.0548\n",
      "Epoch [2525/3000], Loss: 4.0536\n",
      "Epoch [2526/3000], Loss: 4.0523\n",
      "Epoch [2527/3000], Loss: 4.0511\n",
      "Epoch [2528/3000], Loss: 4.0498\n",
      "Epoch [2529/3000], Loss: 4.0486\n",
      "Epoch [2530/3000], Loss: 4.0473\n",
      "Epoch [2531/3000], Loss: 4.0461\n",
      "Epoch [2532/3000], Loss: 4.0448\n",
      "Epoch [2533/3000], Loss: 4.0436\n",
      "Epoch [2534/3000], Loss: 4.0423\n",
      "Epoch [2535/3000], Loss: 4.0411\n",
      "Epoch [2536/3000], Loss: 4.0399\n",
      "Epoch [2537/3000], Loss: 4.0386\n",
      "Epoch [2538/3000], Loss: 4.0374\n",
      "Epoch [2539/3000], Loss: 4.0362\n",
      "Epoch [2540/3000], Loss: 4.0349\n",
      "Epoch [2541/3000], Loss: 4.0337\n",
      "Epoch [2542/3000], Loss: 4.0325\n",
      "Epoch [2543/3000], Loss: 4.0313\n",
      "Epoch [2544/3000], Loss: 4.0301\n",
      "Epoch [2545/3000], Loss: 4.0288\n",
      "Epoch [2546/3000], Loss: 4.0276\n",
      "Epoch [2547/3000], Loss: 4.0264\n",
      "Epoch [2548/3000], Loss: 4.0252\n",
      "Epoch [2549/3000], Loss: 4.0240\n",
      "Epoch [2550/3000], Loss: 4.0228\n",
      "Epoch [2551/3000], Loss: 4.0216\n",
      "Epoch [2552/3000], Loss: 4.0204\n",
      "Epoch [2553/3000], Loss: 4.0192\n",
      "Epoch [2554/3000], Loss: 4.0180\n",
      "Epoch [2555/3000], Loss: 4.0168\n",
      "Epoch [2556/3000], Loss: 4.0156\n",
      "Epoch [2557/3000], Loss: 4.0144\n",
      "Epoch [2558/3000], Loss: 4.0132\n",
      "Epoch [2559/3000], Loss: 4.0120\n",
      "Epoch [2560/3000], Loss: 4.0109\n",
      "Epoch [2561/3000], Loss: 4.0097\n",
      "Epoch [2562/3000], Loss: 4.0086\n",
      "Epoch [2563/3000], Loss: 4.0074\n",
      "Epoch [2564/3000], Loss: 4.0063\n",
      "Epoch [2565/3000], Loss: 4.0053\n",
      "Epoch [2566/3000], Loss: 4.0042\n",
      "Epoch [2567/3000], Loss: 4.0032\n",
      "Epoch [2568/3000], Loss: 4.0022\n",
      "Epoch [2569/3000], Loss: 4.0012\n",
      "Epoch [2570/3000], Loss: 4.0001\n",
      "Epoch [2571/3000], Loss: 3.9991\n",
      "Epoch [2572/3000], Loss: 3.9979\n",
      "Epoch [2573/3000], Loss: 3.9966\n",
      "Epoch [2574/3000], Loss: 3.9953\n",
      "Epoch [2575/3000], Loss: 3.9938\n",
      "Epoch [2576/3000], Loss: 3.9922\n",
      "Epoch [2577/3000], Loss: 3.9906\n",
      "Epoch [2578/3000], Loss: 3.9891\n",
      "Epoch [2579/3000], Loss: 3.9877\n",
      "Epoch [2580/3000], Loss: 3.9865\n",
      "Epoch [2581/3000], Loss: 3.9854\n",
      "Epoch [2582/3000], Loss: 3.9844\n",
      "Epoch [2583/3000], Loss: 3.9833\n",
      "Epoch [2584/3000], Loss: 3.9822\n",
      "Epoch [2585/3000], Loss: 3.9810\n",
      "Epoch [2586/3000], Loss: 3.9797\n",
      "Epoch [2587/3000], Loss: 3.9785\n",
      "Epoch [2588/3000], Loss: 3.9772\n",
      "Epoch [2589/3000], Loss: 3.9759\n",
      "Epoch [2590/3000], Loss: 3.9747\n",
      "Epoch [2591/3000], Loss: 3.9734\n",
      "Epoch [2592/3000], Loss: 3.9723\n",
      "Epoch [2593/3000], Loss: 3.9711\n",
      "Epoch [2594/3000], Loss: 3.9700\n",
      "Epoch [2595/3000], Loss: 3.9689\n",
      "Epoch [2596/3000], Loss: 3.9677\n",
      "Epoch [2597/3000], Loss: 3.9666\n",
      "Epoch [2598/3000], Loss: 3.9654\n",
      "Epoch [2599/3000], Loss: 3.9642\n",
      "Epoch [2600/3000], Loss: 3.9630\n",
      "Epoch [2601/3000], Loss: 3.9617\n",
      "Epoch [2602/3000], Loss: 3.9605\n",
      "Epoch [2603/3000], Loss: 3.9592\n",
      "Epoch [2604/3000], Loss: 3.9580\n",
      "Epoch [2605/3000], Loss: 3.9568\n",
      "Epoch [2606/3000], Loss: 3.9556\n",
      "Epoch [2607/3000], Loss: 3.9544\n",
      "Epoch [2608/3000], Loss: 3.9532\n",
      "Epoch [2609/3000], Loss: 3.9520\n",
      "Epoch [2610/3000], Loss: 3.9509\n",
      "Epoch [2611/3000], Loss: 3.9497\n",
      "Epoch [2612/3000], Loss: 3.9485\n",
      "Epoch [2613/3000], Loss: 3.9473\n",
      "Epoch [2614/3000], Loss: 3.9462\n",
      "Epoch [2615/3000], Loss: 3.9450\n",
      "Epoch [2616/3000], Loss: 3.9438\n",
      "Epoch [2617/3000], Loss: 3.9426\n",
      "Epoch [2618/3000], Loss: 3.9414\n",
      "Epoch [2619/3000], Loss: 3.9402\n",
      "Epoch [2620/3000], Loss: 3.9390\n",
      "Epoch [2621/3000], Loss: 3.9378\n",
      "Epoch [2622/3000], Loss: 3.9366\n",
      "Epoch [2623/3000], Loss: 3.9354\n",
      "Epoch [2624/3000], Loss: 3.9342\n",
      "Epoch [2625/3000], Loss: 3.9330\n",
      "Epoch [2626/3000], Loss: 3.9318\n",
      "Epoch [2627/3000], Loss: 3.9306\n",
      "Epoch [2628/3000], Loss: 3.9294\n",
      "Epoch [2629/3000], Loss: 3.9282\n",
      "Epoch [2630/3000], Loss: 3.9270\n",
      "Epoch [2631/3000], Loss: 3.9258\n",
      "Epoch [2632/3000], Loss: 3.9247\n",
      "Epoch [2633/3000], Loss: 3.9235\n",
      "Epoch [2634/3000], Loss: 3.9223\n",
      "Epoch [2635/3000], Loss: 3.9211\n",
      "Epoch [2636/3000], Loss: 3.9200\n",
      "Epoch [2637/3000], Loss: 3.9189\n",
      "Epoch [2638/3000], Loss: 3.9178\n",
      "Epoch [2639/3000], Loss: 3.9167\n",
      "Epoch [2640/3000], Loss: 3.9156\n",
      "Epoch [2641/3000], Loss: 3.9145\n",
      "Epoch [2642/3000], Loss: 3.9135\n",
      "Epoch [2643/3000], Loss: 3.9125\n",
      "Epoch [2644/3000], Loss: 3.9116\n",
      "Epoch [2645/3000], Loss: 3.9106\n",
      "Epoch [2646/3000], Loss: 3.9097\n",
      "Epoch [2647/3000], Loss: 3.9088\n",
      "Epoch [2648/3000], Loss: 3.9078\n",
      "Epoch [2649/3000], Loss: 3.9067\n",
      "Epoch [2650/3000], Loss: 3.9054\n",
      "Epoch [2651/3000], Loss: 3.9041\n",
      "Epoch [2652/3000], Loss: 3.9025\n",
      "Epoch [2653/3000], Loss: 3.9009\n",
      "Epoch [2654/3000], Loss: 3.8993\n",
      "Epoch [2655/3000], Loss: 3.8978\n",
      "Epoch [2656/3000], Loss: 3.8965\n",
      "Epoch [2657/3000], Loss: 3.8953\n",
      "Epoch [2658/3000], Loss: 3.8943\n",
      "Epoch [2659/3000], Loss: 3.8933\n",
      "Epoch [2660/3000], Loss: 3.8923\n",
      "Epoch [2661/3000], Loss: 3.8912\n",
      "Epoch [2662/3000], Loss: 3.8901\n",
      "Epoch [2663/3000], Loss: 3.8889\n",
      "Epoch [2664/3000], Loss: 3.8876\n",
      "Epoch [2665/3000], Loss: 3.8864\n",
      "Epoch [2666/3000], Loss: 3.8851\n",
      "Epoch [2667/3000], Loss: 3.8838\n",
      "Epoch [2668/3000], Loss: 3.8825\n",
      "Epoch [2669/3000], Loss: 3.8813\n",
      "Epoch [2670/3000], Loss: 3.8801\n",
      "Epoch [2671/3000], Loss: 3.8790\n",
      "Epoch [2672/3000], Loss: 3.8778\n",
      "Epoch [2673/3000], Loss: 3.8767\n",
      "Epoch [2674/3000], Loss: 3.8756\n",
      "Epoch [2675/3000], Loss: 3.8744\n",
      "Epoch [2676/3000], Loss: 3.8733\n",
      "Epoch [2677/3000], Loss: 3.8722\n",
      "Epoch [2678/3000], Loss: 3.8710\n",
      "Epoch [2679/3000], Loss: 3.8698\n",
      "Epoch [2680/3000], Loss: 3.8686\n",
      "Epoch [2681/3000], Loss: 3.8675\n",
      "Epoch [2682/3000], Loss: 3.8663\n",
      "Epoch [2683/3000], Loss: 3.8651\n",
      "Epoch [2684/3000], Loss: 3.8640\n",
      "Epoch [2685/3000], Loss: 3.8628\n",
      "Epoch [2686/3000], Loss: 3.8617\n",
      "Epoch [2687/3000], Loss: 3.8605\n",
      "Epoch [2688/3000], Loss: 3.8594\n",
      "Epoch [2689/3000], Loss: 3.8583\n",
      "Epoch [2690/3000], Loss: 3.8571\n",
      "Epoch [2691/3000], Loss: 3.8560\n",
      "Epoch [2692/3000], Loss: 3.8549\n",
      "Epoch [2693/3000], Loss: 3.8538\n",
      "Epoch [2694/3000], Loss: 3.8526\n",
      "Epoch [2695/3000], Loss: 3.8515\n",
      "Epoch [2696/3000], Loss: 3.8504\n",
      "Epoch [2697/3000], Loss: 3.8493\n",
      "Epoch [2698/3000], Loss: 3.8482\n",
      "Epoch [2699/3000], Loss: 3.8470\n",
      "Epoch [2700/3000], Loss: 3.8459\n",
      "Epoch [2701/3000], Loss: 3.8448\n",
      "Epoch [2702/3000], Loss: 3.8437\n",
      "Epoch [2703/3000], Loss: 3.8426\n",
      "Epoch [2704/3000], Loss: 3.8415\n",
      "Epoch [2705/3000], Loss: 3.8404\n",
      "Epoch [2706/3000], Loss: 3.8393\n",
      "Epoch [2707/3000], Loss: 3.8382\n",
      "Epoch [2708/3000], Loss: 3.8371\n",
      "Epoch [2709/3000], Loss: 3.8361\n",
      "Epoch [2710/3000], Loss: 3.8350\n",
      "Epoch [2711/3000], Loss: 3.8339\n",
      "Epoch [2712/3000], Loss: 3.8329\n",
      "Epoch [2713/3000], Loss: 3.8319\n",
      "Epoch [2714/3000], Loss: 3.8308\n",
      "Epoch [2715/3000], Loss: 3.8298\n",
      "Epoch [2716/3000], Loss: 3.8287\n",
      "Epoch [2717/3000], Loss: 3.8277\n",
      "Epoch [2718/3000], Loss: 3.8266\n",
      "Epoch [2719/3000], Loss: 3.8255\n",
      "Epoch [2720/3000], Loss: 3.8243\n",
      "Epoch [2721/3000], Loss: 3.8232\n",
      "Epoch [2722/3000], Loss: 3.8221\n",
      "Epoch [2723/3000], Loss: 3.8209\n",
      "Epoch [2724/3000], Loss: 3.8198\n",
      "Epoch [2725/3000], Loss: 3.8187\n",
      "Epoch [2726/3000], Loss: 3.8175\n",
      "Epoch [2727/3000], Loss: 3.8164\n",
      "Epoch [2728/3000], Loss: 3.8153\n",
      "Epoch [2729/3000], Loss: 3.8142\n",
      "Epoch [2730/3000], Loss: 3.8131\n",
      "Epoch [2731/3000], Loss: 3.8120\n",
      "Epoch [2732/3000], Loss: 3.8109\n",
      "Epoch [2733/3000], Loss: 3.8098\n",
      "Epoch [2734/3000], Loss: 3.8088\n",
      "Epoch [2735/3000], Loss: 3.8077\n",
      "Epoch [2736/3000], Loss: 3.8066\n",
      "Epoch [2737/3000], Loss: 3.8056\n",
      "Epoch [2738/3000], Loss: 3.8045\n",
      "Epoch [2739/3000], Loss: 3.8034\n",
      "Epoch [2740/3000], Loss: 3.8024\n",
      "Epoch [2741/3000], Loss: 3.8013\n",
      "Epoch [2742/3000], Loss: 3.8003\n",
      "Epoch [2743/3000], Loss: 3.7992\n",
      "Epoch [2744/3000], Loss: 3.7982\n",
      "Epoch [2745/3000], Loss: 3.7971\n",
      "Epoch [2746/3000], Loss: 3.7960\n",
      "Epoch [2747/3000], Loss: 3.7950\n",
      "Epoch [2748/3000], Loss: 3.7939\n",
      "Epoch [2749/3000], Loss: 3.7929\n",
      "Epoch [2750/3000], Loss: 3.7918\n",
      "Epoch [2751/3000], Loss: 3.7908\n",
      "Epoch [2752/3000], Loss: 3.7897\n",
      "Epoch [2753/3000], Loss: 3.7886\n",
      "Epoch [2754/3000], Loss: 3.7876\n",
      "Epoch [2755/3000], Loss: 3.7865\n",
      "Epoch [2756/3000], Loss: 3.7855\n",
      "Epoch [2757/3000], Loss: 3.7844\n",
      "Epoch [2758/3000], Loss: 3.7834\n",
      "Epoch [2759/3000], Loss: 3.7824\n",
      "Epoch [2760/3000], Loss: 3.7813\n",
      "Epoch [2761/3000], Loss: 3.7803\n",
      "Epoch [2762/3000], Loss: 3.7792\n",
      "Epoch [2763/3000], Loss: 3.7782\n",
      "Epoch [2764/3000], Loss: 3.7771\n",
      "Epoch [2765/3000], Loss: 3.7761\n",
      "Epoch [2766/3000], Loss: 3.7750\n",
      "Epoch [2767/3000], Loss: 3.7740\n",
      "Epoch [2768/3000], Loss: 3.7730\n",
      "Epoch [2769/3000], Loss: 3.7719\n",
      "Epoch [2770/3000], Loss: 3.7709\n",
      "Epoch [2771/3000], Loss: 3.7700\n",
      "Epoch [2772/3000], Loss: 3.7691\n",
      "Epoch [2773/3000], Loss: 3.7682\n",
      "Epoch [2774/3000], Loss: 3.7675\n",
      "Epoch [2775/3000], Loss: 3.7670\n",
      "Epoch [2776/3000], Loss: 3.7668\n",
      "Epoch [2777/3000], Loss: 3.7671\n",
      "Epoch [2778/3000], Loss: 3.7680\n",
      "Epoch [2779/3000], Loss: 3.7697\n",
      "Epoch [2780/3000], Loss: 3.7715\n",
      "Epoch [2781/3000], Loss: 3.7720\n",
      "Epoch [2782/3000], Loss: 3.7694\n",
      "Epoch [2783/3000], Loss: 3.7639\n",
      "Epoch [2784/3000], Loss: 3.7582\n",
      "Epoch [2785/3000], Loss: 3.7556\n",
      "Epoch [2786/3000], Loss: 3.7565\n",
      "Epoch [2787/3000], Loss: 3.7583\n",
      "Epoch [2788/3000], Loss: 3.7581\n",
      "Epoch [2789/3000], Loss: 3.7551\n",
      "Epoch [2790/3000], Loss: 3.7514\n",
      "Epoch [2791/3000], Loss: 3.7497\n",
      "Epoch [2792/3000], Loss: 3.7501\n",
      "Epoch [2793/3000], Loss: 3.7506\n",
      "Epoch [2794/3000], Loss: 3.7493\n",
      "Epoch [2795/3000], Loss: 3.7468\n",
      "Epoch [2796/3000], Loss: 3.7448\n",
      "Epoch [2797/3000], Loss: 3.7443\n",
      "Epoch [2798/3000], Loss: 3.7443\n",
      "Epoch [2799/3000], Loss: 3.7436\n",
      "Epoch [2800/3000], Loss: 3.7418\n",
      "Epoch [2801/3000], Loss: 3.7401\n",
      "Epoch [2802/3000], Loss: 3.7392\n",
      "Epoch [2803/3000], Loss: 3.7388\n",
      "Epoch [2804/3000], Loss: 3.7381\n",
      "Epoch [2805/3000], Loss: 3.7368\n",
      "Epoch [2806/3000], Loss: 3.7354\n",
      "Epoch [2807/3000], Loss: 3.7343\n",
      "Epoch [2808/3000], Loss: 3.7337\n",
      "Epoch [2809/3000], Loss: 3.7330\n",
      "Epoch [2810/3000], Loss: 3.7319\n",
      "Epoch [2811/3000], Loss: 3.7306\n",
      "Epoch [2812/3000], Loss: 3.7296\n",
      "Epoch [2813/3000], Loss: 3.7287\n",
      "Epoch [2814/3000], Loss: 3.7280\n",
      "Epoch [2815/3000], Loss: 3.7270\n",
      "Epoch [2816/3000], Loss: 3.7259\n",
      "Epoch [2817/3000], Loss: 3.7248\n",
      "Epoch [2818/3000], Loss: 3.7239\n",
      "Epoch [2819/3000], Loss: 3.7231\n",
      "Epoch [2820/3000], Loss: 3.7222\n",
      "Epoch [2821/3000], Loss: 3.7212\n",
      "Epoch [2822/3000], Loss: 3.7202\n",
      "Epoch [2823/3000], Loss: 3.7192\n",
      "Epoch [2824/3000], Loss: 3.7184\n",
      "Epoch [2825/3000], Loss: 3.7175\n",
      "Epoch [2826/3000], Loss: 3.7165\n",
      "Epoch [2827/3000], Loss: 3.7155\n",
      "Epoch [2828/3000], Loss: 3.7146\n",
      "Epoch [2829/3000], Loss: 3.7137\n",
      "Epoch [2830/3000], Loss: 3.7128\n",
      "Epoch [2831/3000], Loss: 3.7118\n",
      "Epoch [2832/3000], Loss: 3.7109\n",
      "Epoch [2833/3000], Loss: 3.7099\n",
      "Epoch [2834/3000], Loss: 3.7090\n",
      "Epoch [2835/3000], Loss: 3.7081\n",
      "Epoch [2836/3000], Loss: 3.7072\n",
      "Epoch [2837/3000], Loss: 3.7062\n",
      "Epoch [2838/3000], Loss: 3.7053\n",
      "Epoch [2839/3000], Loss: 3.7044\n",
      "Epoch [2840/3000], Loss: 3.7034\n",
      "Epoch [2841/3000], Loss: 3.7025\n",
      "Epoch [2842/3000], Loss: 3.7016\n",
      "Epoch [2843/3000], Loss: 3.7007\n",
      "Epoch [2844/3000], Loss: 3.6998\n",
      "Epoch [2845/3000], Loss: 3.6988\n",
      "Epoch [2846/3000], Loss: 3.6979\n",
      "Epoch [2847/3000], Loss: 3.6970\n",
      "Epoch [2848/3000], Loss: 3.6961\n",
      "Epoch [2849/3000], Loss: 3.6952\n",
      "Epoch [2850/3000], Loss: 3.6943\n",
      "Epoch [2851/3000], Loss: 3.6934\n",
      "Epoch [2852/3000], Loss: 3.6925\n",
      "Epoch [2853/3000], Loss: 3.6916\n",
      "Epoch [2854/3000], Loss: 3.6907\n",
      "Epoch [2855/3000], Loss: 3.6898\n",
      "Epoch [2856/3000], Loss: 3.6889\n",
      "Epoch [2857/3000], Loss: 3.6880\n",
      "Epoch [2858/3000], Loss: 3.6871\n",
      "Epoch [2859/3000], Loss: 3.6862\n",
      "Epoch [2860/3000], Loss: 3.6853\n",
      "Epoch [2861/3000], Loss: 3.6844\n",
      "Epoch [2862/3000], Loss: 3.6835\n",
      "Epoch [2863/3000], Loss: 3.6826\n",
      "Epoch [2864/3000], Loss: 3.6817\n",
      "Epoch [2865/3000], Loss: 3.6808\n",
      "Epoch [2866/3000], Loss: 3.6799\n",
      "Epoch [2867/3000], Loss: 3.6790\n",
      "Epoch [2868/3000], Loss: 3.6781\n",
      "Epoch [2869/3000], Loss: 3.6772\n",
      "Epoch [2870/3000], Loss: 3.6763\n",
      "Epoch [2871/3000], Loss: 3.6754\n",
      "Epoch [2872/3000], Loss: 3.6745\n",
      "Epoch [2873/3000], Loss: 3.6736\n",
      "Epoch [2874/3000], Loss: 3.6727\n",
      "Epoch [2875/3000], Loss: 3.6718\n",
      "Epoch [2876/3000], Loss: 3.6710\n",
      "Epoch [2877/3000], Loss: 3.6701\n",
      "Epoch [2878/3000], Loss: 3.6692\n",
      "Epoch [2879/3000], Loss: 3.6683\n",
      "Epoch [2880/3000], Loss: 3.6674\n",
      "Epoch [2881/3000], Loss: 3.6665\n",
      "Epoch [2882/3000], Loss: 3.6656\n",
      "Epoch [2883/3000], Loss: 3.6647\n",
      "Epoch [2884/3000], Loss: 3.6638\n",
      "Epoch [2885/3000], Loss: 3.6630\n",
      "Epoch [2886/3000], Loss: 3.6621\n",
      "Epoch [2887/3000], Loss: 3.6612\n",
      "Epoch [2888/3000], Loss: 3.6603\n",
      "Epoch [2889/3000], Loss: 3.6594\n",
      "Epoch [2890/3000], Loss: 3.6585\n",
      "Epoch [2891/3000], Loss: 3.6576\n",
      "Epoch [2892/3000], Loss: 3.6567\n",
      "Epoch [2893/3000], Loss: 3.6559\n",
      "Epoch [2894/3000], Loss: 3.6550\n",
      "Epoch [2895/3000], Loss: 3.6541\n",
      "Epoch [2896/3000], Loss: 3.6532\n",
      "Epoch [2897/3000], Loss: 3.6523\n",
      "Epoch [2898/3000], Loss: 3.6515\n",
      "Epoch [2899/3000], Loss: 3.6506\n",
      "Epoch [2900/3000], Loss: 3.6497\n",
      "Epoch [2901/3000], Loss: 3.6488\n",
      "Epoch [2902/3000], Loss: 3.6480\n",
      "Epoch [2903/3000], Loss: 3.6471\n",
      "Epoch [2904/3000], Loss: 3.6462\n",
      "Epoch [2905/3000], Loss: 3.6453\n",
      "Epoch [2906/3000], Loss: 3.6444\n",
      "Epoch [2907/3000], Loss: 3.6436\n",
      "Epoch [2908/3000], Loss: 3.6427\n",
      "Epoch [2909/3000], Loss: 3.6418\n",
      "Epoch [2910/3000], Loss: 3.6409\n",
      "Epoch [2911/3000], Loss: 3.6401\n",
      "Epoch [2912/3000], Loss: 3.6392\n",
      "Epoch [2913/3000], Loss: 3.6383\n",
      "Epoch [2914/3000], Loss: 3.6375\n",
      "Epoch [2915/3000], Loss: 3.6366\n",
      "Epoch [2916/3000], Loss: 3.6357\n",
      "Epoch [2917/3000], Loss: 3.6349\n",
      "Epoch [2918/3000], Loss: 3.6340\n",
      "Epoch [2919/3000], Loss: 3.6331\n",
      "Epoch [2920/3000], Loss: 3.6322\n",
      "Epoch [2921/3000], Loss: 3.6314\n",
      "Epoch [2922/3000], Loss: 3.6305\n",
      "Epoch [2923/3000], Loss: 3.6296\n",
      "Epoch [2924/3000], Loss: 3.6288\n",
      "Epoch [2925/3000], Loss: 3.6279\n",
      "Epoch [2926/3000], Loss: 3.6271\n",
      "Epoch [2927/3000], Loss: 3.6262\n",
      "Epoch [2928/3000], Loss: 3.6254\n",
      "Epoch [2929/3000], Loss: 3.6245\n",
      "Epoch [2930/3000], Loss: 3.6236\n",
      "Epoch [2931/3000], Loss: 3.6228\n",
      "Epoch [2932/3000], Loss: 3.6219\n",
      "Epoch [2933/3000], Loss: 3.6211\n",
      "Epoch [2934/3000], Loss: 3.6202\n",
      "Epoch [2935/3000], Loss: 3.6194\n",
      "Epoch [2936/3000], Loss: 3.6185\n",
      "Epoch [2937/3000], Loss: 3.6177\n",
      "Epoch [2938/3000], Loss: 3.6168\n",
      "Epoch [2939/3000], Loss: 3.6160\n",
      "Epoch [2940/3000], Loss: 3.6152\n",
      "Epoch [2941/3000], Loss: 3.6143\n",
      "Epoch [2942/3000], Loss: 3.6135\n",
      "Epoch [2943/3000], Loss: 3.6126\n",
      "Epoch [2944/3000], Loss: 3.6118\n",
      "Epoch [2945/3000], Loss: 3.6110\n",
      "Epoch [2946/3000], Loss: 3.6101\n",
      "Epoch [2947/3000], Loss: 3.6093\n",
      "Epoch [2948/3000], Loss: 3.6084\n",
      "Epoch [2949/3000], Loss: 3.6076\n",
      "Epoch [2950/3000], Loss: 3.6068\n",
      "Epoch [2951/3000], Loss: 3.6060\n",
      "Epoch [2952/3000], Loss: 3.6051\n",
      "Epoch [2953/3000], Loss: 3.6043\n",
      "Epoch [2954/3000], Loss: 3.6035\n",
      "Epoch [2955/3000], Loss: 3.6026\n",
      "Epoch [2956/3000], Loss: 3.6018\n",
      "Epoch [2957/3000], Loss: 3.6010\n",
      "Epoch [2958/3000], Loss: 3.6001\n",
      "Epoch [2959/3000], Loss: 3.5993\n",
      "Epoch [2960/3000], Loss: 3.5985\n",
      "Epoch [2961/3000], Loss: 3.5977\n",
      "Epoch [2962/3000], Loss: 3.5969\n",
      "Epoch [2963/3000], Loss: 3.5960\n",
      "Epoch [2964/3000], Loss: 3.5952\n",
      "Epoch [2965/3000], Loss: 3.5944\n",
      "Epoch [2966/3000], Loss: 3.5936\n",
      "Epoch [2967/3000], Loss: 3.5928\n",
      "Epoch [2968/3000], Loss: 3.5920\n",
      "Epoch [2969/3000], Loss: 3.5912\n",
      "Epoch [2970/3000], Loss: 3.5904\n",
      "Epoch [2971/3000], Loss: 3.5896\n",
      "Epoch [2972/3000], Loss: 3.5888\n",
      "Epoch [2973/3000], Loss: 3.5880\n",
      "Epoch [2974/3000], Loss: 3.5872\n",
      "Epoch [2975/3000], Loss: 3.5864\n",
      "Epoch [2976/3000], Loss: 3.5856\n",
      "Epoch [2977/3000], Loss: 3.5848\n",
      "Epoch [2978/3000], Loss: 3.5840\n",
      "Epoch [2979/3000], Loss: 3.5832\n",
      "Epoch [2980/3000], Loss: 3.5825\n",
      "Epoch [2981/3000], Loss: 3.5817\n",
      "Epoch [2982/3000], Loss: 3.5810\n",
      "Epoch [2983/3000], Loss: 3.5802\n",
      "Epoch [2984/3000], Loss: 3.5795\n",
      "Epoch [2985/3000], Loss: 3.5788\n",
      "Epoch [2986/3000], Loss: 3.5780\n",
      "Epoch [2987/3000], Loss: 3.5773\n",
      "Epoch [2988/3000], Loss: 3.5766\n",
      "Epoch [2989/3000], Loss: 3.5758\n",
      "Epoch [2990/3000], Loss: 3.5751\n",
      "Epoch [2991/3000], Loss: 3.5744\n",
      "Epoch [2992/3000], Loss: 3.5737\n",
      "Epoch [2993/3000], Loss: 3.5729\n",
      "Epoch [2994/3000], Loss: 3.5722\n",
      "Epoch [2995/3000], Loss: 3.5713\n",
      "Epoch [2996/3000], Loss: 3.5705\n",
      "Epoch [2997/3000], Loss: 3.5696\n",
      "Epoch [2998/3000], Loss: 3.5687\n",
      "Epoch [2999/3000], Loss: 3.5678\n",
      "Epoch [3000/3000], Loss: 3.5668\n"
     ]
    }
   ],
   "source": [
    "train_model(model, X_train.to(device), y_train.to(device),\n",
    "            mask_train.to(device), criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, X_test, y_test):\n",
    "    model.eval()  # Переводим модель в режим оценки\n",
    "\n",
    "    # Маска для строк без NaN в X_test\n",
    "    valid_mask = ~torch.isnan(X_test).any(dim=1)\n",
    "\n",
    "    # Применяем маску к тестовым данным и целевым значениям\n",
    "    X_test_valid = X_test[valid_mask]\n",
    "    y_test_valid = y_test[valid_mask]\n",
    "\n",
    "    # Получаем предсказания модели\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test_valid)\n",
    "\n",
    "    # Вычисляем отклонения\n",
    "    mae = torch.mean(torch.abs(y_pred - y_test_valid))\n",
    "    mse = torch.mean((y_pred - y_test_valid) ** 2)\n",
    "\n",
    "    print(f\"Test MAE: {mae.item():.4f}\")\n",
    "    print(f\"Test MSE: {mse.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 1.3739\n",
      "Test MSE: 3.4130\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "test_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
